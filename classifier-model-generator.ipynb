{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from predictionhelper.ipynb\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pylab import *\n",
    "\n",
    "import pickle\n",
    "import loadnotebook\n",
    "from predictionhelper import *\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn.metrics as metric\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [x for x in range(1, 34)]\n",
    "demo_config = {6 : sets}\n",
    "\n",
    "df_data = get_data(config=demo_config, pure=True, refresh=False).reset_index(drop=True)\n",
    "print(len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pci_data = df_data[df_data[\"PCI\"].isin(whitelist_PCI)]\n",
    "beam_columns = [c for c in df_data if \"beam\" in c]\n",
    "pci_data = pci_data.drop([\"RSRP\", \"RSRQ\", \"SNR\"]+beam_columns, axis=1)\n",
    "pci_data = pci_data.drop_duplicates()\n",
    "pci_data = pci_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6356 2745\n"
     ]
    }
   ],
   "source": [
    "pci_train, pci_test = pd.DataFrame(), pd.DataFrame()\n",
    "pci_train_dict, pci_test_dict = {}, {}\n",
    "for p in demo_config :\n",
    "    for s in demo_config[p] :\n",
    "        a, b = train_test_split(pci_data[pci_data.set==s], test_size=0.3, random_state=32)\n",
    "        pci_train = pci_train.append(a)\n",
    "        pci_test = pci_test.append(b)  \n",
    "        pci_train_dict[(p, s)] = a\n",
    "        pci_test_dict[(p, s)] = b\n",
    "print(len(pci_train), len(pci_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pci_train = pci_train.drop([\"PCI\"], axis=1)\n",
    "y_pci_train = np.array(pci_train.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "x_pci_test = pci_test.drop([\"PCI\"], axis=1)\n",
    "y_pci_test = np.array(pci_test.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "\n",
    "x_pci_train_dict, y_pci_train_dict, x_pci_test_dict, y_pci_test_dict = {}, {}, {}, {}\n",
    "for p in demo_config :\n",
    "    for s in demo_config[p] :\n",
    "        a, b = pci_train_dict[(p,s)], pci_test_dict[(p,s)]\n",
    "        x_pci_train_dict[(p, s)] = a.drop([\"PCI\"], axis=1)\n",
    "        y_pci_train_dict[(p, s)] = np.array(a.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "        x_pci_test_dict[(p, s)] = b.drop([\"PCI\"], axis=1)\n",
    "        y_pci_test_dict[(p, s)] = np.array(b.PCI.apply(lambda x : pci_encode[x]).values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class svm_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {}\n",
    "        params['C'] = param['C'] if param['C'] > 0 else 0.1\n",
    "        params['random_state'] = int(param['random_state'])\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, C=1.0, random_state=0):\n",
    "        params = {'C':C, 'random_state':random_state}\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        model = svm.LinearSVC(**params)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pred = model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26775956284153\n"
     ]
    }
   ],
   "source": [
    "svm_params = {'random_state':0}\n",
    "model = svm.LinearSVC(**svm_params)\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.weights = ['uniform', 'distance']\n",
    "        self.algorithms = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {'n_neighbors':7}\n",
    "        params['weights'] = self.weights[int(param['weight'])]\n",
    "        params['algorithm'] = self.algorithms[int(param['algorithm'])]\n",
    "        params['leaf_size'] = int(param['leaf_size'])\n",
    "        params['p'] = int(param['p'])\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, weight, algorithm, leaf_size=100, p=2):\n",
    "        params = {}\n",
    "        params['weight'] = weight\n",
    "        params['algorithm'] = algorithm\n",
    "        params['leaf_size'] = int(leaf_size)\n",
    "        params['p'] = int(p)\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        model = KNeighborsClassifier(**params)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kt = knn_target(x_pci_train[location_col], y_pci_train, \n",
    "#                 x_pci_test[location_col], y_pci_test)\n",
    "# kBO = BayesianOptimization(kt.evaluate, {'weight': (0, 1),\n",
    "#                                         'algorithm' : (0, 3),\n",
    "#                                         'leaf_size' : (5, 50),\n",
    "#                                         'p': (1, 2),},\n",
    "#                             random_state = 1)\n",
    "\n",
    "# kBO.maximize(init_points=20, n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7,\n",
       " 'weights': 'uniform',\n",
       " 'algorithm': 'kd_tree',\n",
       " 'leaf_size': 49,\n",
       " 'p': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = kt.clean_param(kBO.res['max']['max_params'])\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': 6,\n",
    " 'weights': 'uniform',\n",
    " 'algorithm': 'kd_tree',\n",
    " 'leaf_size': 49,\n",
    " 'p': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3067395264116576\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(**knn_params)\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xgboost_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        booster_dict = {1:'gbtree', 2:'gblinear', 3:'dart'}\n",
    "        params = {'base_score':0.5, 'booster':'gbtree', 'missing':None, 'n_estimators':100, \n",
    "                  'n_jobs':1, 'objective':'multi:softmax', 'random_state':1, \n",
    "                  'reg_lambda':1, 'alpha':0, 'scale_pos_weight':1, \n",
    "                  'subsample':1, 'colsample_bytree':1, 'colsample_bylevel':1}\n",
    "\n",
    "        params['learning_rate'] = param['learning_rate']/100\n",
    "        params['booster'] = booster_dict[int(param['booster'])]\n",
    "        params['gamma'] = param['gamma']\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['min_child_weight'] = int(param['min_child_weight'])\n",
    "        params['max_delta_weight'] = int(param['max_delta_weight'])\n",
    "        params['rate_drop'] = param['rate_drop']\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, learning_rate, booster, gamma, max_depth,  \n",
    "                     min_child_weight, max_delta_weight, rate_drop):\n",
    "\n",
    "        params = {}\n",
    "        params['learning_rate'] = learning_rate\n",
    "        params['booster'] = booster\n",
    "        params['gamma'] = gamma\n",
    "        params['max_depth'] = max_depth\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['max_delta_weight'] = max_delta_weight\n",
    "        params['rate_drop'] = rate_drop\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        xgb_model = XGBClassifier(**params)\n",
    "        xgb_model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = xgb_model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   booster |     gamma |   learning_rate |   max_delta_weight |   max_depth |   min_child_weight |   rate_drop | \n",
      "    1 | 00m03s | \u001b[35m   0.73807\u001b[0m | \u001b[32m   1.8384\u001b[0m | \u001b[32m  40.0372\u001b[0m | \u001b[32m         5.5872\u001b[0m | \u001b[32m            1.3680\u001b[0m | \u001b[32m     3.8851\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.1023\u001b[0m | \n",
      "    2 | 00m00s |    0.69945 |    2.3704 |   48.4131 |          8.9236 |            13.8979 |      6.7900 |             1.0000 |      0.4141 | \n",
      "    3 | 00m09s | \u001b[35m   0.74026\u001b[0m | \u001b[32m   1.4089\u001b[0m | \u001b[32m  15.6712\u001b[0m | \u001b[32m         1.0013\u001b[0m | \u001b[32m            5.0209\u001b[0m | \u001b[32m    11.6210\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.6944\u001b[0m | \n",
      "    4 | 00m00s |    0.66485 |    2.7562 |   34.6161 |          4.3257 |             6.0454 |      7.7985 |             1.0000 |      0.4142 | \n",
      "    5 | 00m09s |    0.73151 |    1.0548 |   43.8195 |          2.6143 |            10.3399 |      9.2269 |             1.0000 |      0.0500 | \n",
      "    6 | 00m00s |    0.58834 |    2.3409 |   44.7303 |          2.0157 |             2.0139 |      5.8396 |             1.0000 |      0.5359 | \n",
      "    7 | 00m08s | \u001b[35m   0.74791\u001b[0m | \u001b[32m   1.8346\u001b[0m | \u001b[32m   4.2522\u001b[0m | \u001b[32m         3.0489\u001b[0m | \u001b[32m           11.9082\u001b[0m | \u001b[32m     9.1785\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.6638\u001b[0m | \n",
      "    8 | 00m00s |    0.67140 |    2.1174 |    1.9527 |          4.8012 |             3.7878 |     10.5116 |             1.0000 |      0.5149 | \n",
      "    9 | 00m03s | \u001b[35m   0.75446\u001b[0m | \u001b[32m   1.2808\u001b[0m | \u001b[32m   8.4915\u001b[0m | \u001b[32m         5.3644\u001b[0m | \u001b[32m           12.1968\u001b[0m | \u001b[32m     3.1646\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.9446\u001b[0m | \n",
      "   10 | 00m08s |    0.73807 |    1.3962 |   43.9071 |          6.9270 |            14.2954 |      9.7513 |             1.0000 |      0.5866 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   booster |     gamma |   learning_rate |   max_delta_weight |   max_depth |   min_child_weight |   rate_drop | \n",
      "   11 | 00m14s |    0.73698 |    1.0000 |   35.4465 |          1.0000 |            20.0000 |      3.0000 |             1.0000 |      0.0000 | \n",
      "   12 | 00m23s |    0.75410 |    1.0000 |    9.8281 |         12.0000 |            20.0000 |     12.0000 |             1.0000 |      0.0000 | \n",
      "   13 | 00m17s |    0.74827 |    1.0000 |   22.9541 |         12.0000 |             1.0000 |      3.0000 |             1.0000 |      0.0000 | \n",
      "   14 | 00m16s |    0.74135 |    1.0000 |    0.0000 |          1.0000 |            20.0000 |      3.0000 |             1.0000 |      0.0000 | \n",
      "   15 | 00m26s |    0.73042 |    1.0000 |   50.0000 |         12.0000 |             1.0000 |     12.0000 |             1.0000 |      0.0000 | \n"
     ]
    }
   ],
   "source": [
    "# xt = xgboost_target(x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "# xgbBO = BayesianOptimization(xt.evaluate, {'learning_rate': (1, 12),\n",
    "#                                             'booster' : (1, 3),\n",
    "#                                             'gamma' : (0, 50),\n",
    "#                                             'max_depth': (3, 12),\n",
    "#                                             'min_child_weight': (1, 1),\n",
    "#                                             'max_delta_weight': (1, 20),\n",
    "#                                             'rate_drop': (0, 1)},\n",
    "#                             random_state = 1)\n",
    "\n",
    "# xgbBO.maximize(init_points=10, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24553734061930788\n"
     ]
    }
   ],
   "source": [
    "# params = xt.clean_param(xgbBO.res['max']['max_params'])\n",
    "# xgb_model = XGBClassifier(**params)\n",
    "# xgb_model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "# y_pci_pred = xgb_model.predict(x_pci_test)\n",
    "# predictions = [round(value) for value in y_pci_pred]\n",
    "# accuracy = accuracy_score(y_pci_test, predictions)\n",
    "# print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {'base_score': 0.5,\n",
    " 'booster': 'gbtree',\n",
    " 'missing': None,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': 1,\n",
    " 'objective': 'multi:softmax',\n",
    " 'random_state': 1,\n",
    " 'reg_lambda': 1,\n",
    " 'alpha': 0,\n",
    " 'scale_pos_weight': 1,\n",
    " 'subsample': 1,\n",
    " 'colsample_bytree': 1,\n",
    " 'colsample_bylevel': 1,\n",
    " 'learning_rate': 0.0536444221653737,\n",
    " 'gamma': 8.491520978228445,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 1,\n",
    " 'max_delta_weight': 12,\n",
    " 'rate_drop': 0.9445947559908133}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24553734061930788\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(**xgboost_params)\n",
    "xgb_model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = xgb_model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lgbm_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {'boosting_type':'gbdt', 'class_weight':None, 'colsample_bytree':1.0, \n",
    "                  'importance_type':'split', \n",
    "                  'min_child_samples':20, 'min_split_gain':0.0, 'n_estimators':100, 'objective':None,\n",
    "                  'random_state':0, 'reg_alpha':0.0, 'reg_lambda':0.0, 'silent':True,\n",
    "                  'subsample':1.0, 'subsample_for_bin':200000, 'subsample_freq':0}\n",
    "        params['num_leaves'] = int(param['num_leaves'])\n",
    "        params['min_child_weight'] = int(param['min_child_weight'])\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['learning_rate'] = param['learning_rate'] / 100\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, min_child_weight, learning_rate, max_depth, num_leaves):\n",
    "        params = {'num_leaves':num_leaves, \n",
    "                  'min_child_weight':min_child_weight, \n",
    "                  'max_depth':max_depth, \n",
    "                  'learning_rate':learning_rate}\n",
    "        \n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        lgbm_model = LGBMClassifier(**params )\n",
    "        lgbm_model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = lgbm_model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   learning_rate |   max_depth |   min_child_weight |   num_leaves | \n",
      "    1 | 00m01s | \u001b[35m   0.74681\u001b[0m | \u001b[32m         3.5517\u001b[0m | \u001b[32m     5.5043\u001b[0m | \u001b[32m            0.5508\u001b[0m | \u001b[32m     21.8120\u001b[0m | \n",
      "    2 | 00m01s |    0.72750 |          7.2382 |      6.5030 |             0.7081 |      35.0661 | \n",
      "    3 | 00m00s | \u001b[35m   0.75519\u001b[0m | \u001b[32m         4.9641\u001b[0m | \u001b[32m     3.3078\u001b[0m | \u001b[32m            0.2909\u001b[0m | \u001b[32m     20.2932\u001b[0m | \n",
      "    4 | 00m00s |    0.74608 |          2.4118 |      3.6687 |             0.5108 |      30.7757 | \n",
      "    5 | 00m01s |    0.74281 |          5.9018 |      6.3230 |             0.8929 |      19.6613 | \n",
      "    6 | 00m01s |    0.71038 |          8.0228 |     12.7685 |             0.8963 |      25.0315 | \n",
      "    7 | 00m00s | \u001b[35m   0.75883\u001b[0m | \u001b[32m         3.7573\u001b[0m | \u001b[32m     8.3800\u001b[0m | \u001b[32m            0.1256\u001b[0m | \u001b[32m      7.7688\u001b[0m | \n",
      "    8 | 00m00s |    0.75118 |          2.9976 |      3.5358 |             0.2072 |      15.9204 | \n",
      "    9 | 00m00s |    0.75337 |          4.4917 |      3.4476 |             0.0515 |      48.7221 | \n",
      "   10 | 00m01s |    0.73406 |          9.4275 |      6.2740 |             0.4408 |      15.3763 | \n",
      "   11 | 00m00s | \u001b[35m   0.75993\u001b[0m | \u001b[32m         9.7840\u001b[0m | \u001b[32m     2.2866\u001b[0m | \u001b[32m            0.0299\u001b[0m | \u001b[32m     36.1165\u001b[0m | \n",
      "   12 | 00m00s |    0.75628 |          7.0515 |      2.2221 |             0.4568 |      34.2715 | \n",
      "   13 | 00m02s |    0.71148 |          9.1255 |      7.2246 |             0.6491 |      37.5773 | \n",
      "   14 | 00m01s |    0.70820 |          8.6118 |      0.3957 |             0.2785 |      26.3790 | \n",
      "   15 | 00m01s |    0.73989 |          4.4019 |      6.7374 |             0.6763 |      31.8499 | \n",
      "   16 | 00m00s |    0.74936 |          1.8300 |      4.7948 |             0.5909 |       8.0136 | \n",
      "   17 | 00m00s |    0.75556 |          6.8807 |     10.3230 |             0.0240 |       8.2653 | \n",
      "   18 | 00m01s |    0.74718 |          6.0206 |     10.9479 |             0.5589 |      13.9539 | \n",
      "   19 | 00m01s |    0.75373 |          4.2541 |     10.0575 |             0.2593 |      11.8337 | \n",
      "   20 | 00m00s |    0.75556 |          3.0255 |     10.0269 |             0.4151 |       9.5047 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   learning_rate |   max_depth |   min_child_weight |   num_leaves | \n",
      "   21 | 00m09s |    0.67505 |          9.6740 |     -0.9912 |             0.4701 |      49.5395 | \n",
      "   22 | 00m09s |    0.73260 |          1.0000 |     15.0000 |             0.0000 |      50.0000 | \n",
      "   23 | 00m09s |    0.72933 |          1.4903 |     -0.9875 |             0.0408 |      43.5635 | \n",
      "   24 | 00m07s |    0.75920 |          9.7273 |     -0.6849 |             0.0916 |       5.2474 | \n",
      "   25 | 00m08s |    0.73953 |          1.0000 |     15.0000 |             0.0000 |       5.0000 | \n"
     ]
    }
   ],
   "source": [
    "# lt = lgbm_target(x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "# lgbmBO = BayesianOptimization(lt.evaluate, {'min_child_weight': (0.01, 1),\n",
    "#                                               'learning_rate': (1, 10),\n",
    "#                                               'max_depth': (-1, 15),\n",
    "#                                               'num_leaves': (5, 50)}, \n",
    "#                              random_state=3)\n",
    "\n",
    "# lgbmBO.maximize(init_points=20, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24007285974499093\n"
     ]
    }
   ],
   "source": [
    "# params = lt.clean_param(lgbmBO.res['max']['max_params'])\n",
    "# lgbm_model = LGBMClassifier(**params )\n",
    "# lgbm_model.fit(x_pci_train, y_pci_train)\n",
    "# y_pci_pred = lgbm_model.predict(x_pci_test)\n",
    "# predictions = [round(value) for value in y_pci_pred]\n",
    "# accuracy = accuracy_score(y_pci_test, predictions)\n",
    "# print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'boosting_type': 'gbdt',\n",
    " 'class_weight': None,\n",
    " 'colsample_bytree': 1.0,\n",
    " 'importance_type': 'split',\n",
    " 'min_child_samples': 20,\n",
    " 'min_split_gain': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'objective': None,\n",
    " 'random_state': 0,\n",
    " 'reg_alpha': 0.0,\n",
    " 'reg_lambda': 0.0,\n",
    " 'silent': True,\n",
    " 'subsample': 1.0,\n",
    " 'subsample_for_bin': 200000,\n",
    " 'subsample_freq': 0,\n",
    " 'num_leaves': 36,\n",
    " 'min_child_weight': 0,\n",
    " 'max_depth': 2,\n",
    " 'learning_rate': 0.09783958802256404}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23970856102003646\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = {'learning_rate' : 0.099387, 'max_depth' : 14, 'min_child_weight':0, 'num_leaves':5}\n",
    "lgbm_model = LGBMClassifier(**lgbm_params)\n",
    "lgbm_model.fit(x_pci_train, y_pci_train)\n",
    "y_pci_pred = lgbm_model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'boosting_type': 'gbdt',\n",
    " 'class_weight': None,\n",
    " 'colsample_bytree': 1.0,\n",
    " 'importance_type': 'split',\n",
    " 'min_child_samples': 20,\n",
    " 'min_split_gain': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'objective': None,\n",
    " 'random_state': 0,\n",
    " 'reg_alpha': 0.0,\n",
    " 'reg_lambda': 0.0,\n",
    " 'silent': True,\n",
    " 'subsample': 1.0,\n",
    " 'subsample_for_bin': 200000,\n",
    " 'subsample_freq': 0,\n",
    " 'num_leaves': 36,\n",
    " 'min_child_weight': 0,\n",
    " 'max_depth': 2,\n",
    " 'learning_rate': 0.09783958802256404}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_matrix = np.empty((4, 3, 34))\n",
    "nrmse_matrix[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test) :\n",
    "    if 'xgb' in model_name : \n",
    "        return xgboost_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    elif 'lgbm' in model_name : \n",
    "        return lgbm_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    elif 'knn' in model_name : \n",
    "        return knn_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    elif 'svm' in model_name : \n",
    "        return svm_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    \n",
    "def get_params_range(model_name) :\n",
    "    if 'xgb' in model_name : \n",
    "        return {'learning_rate': (1, 12),\n",
    "                'booster' : (1, 3),\n",
    "                'gamma' : (0, 5),\n",
    "                'max_depth': (3, 10),\n",
    "                'min_child_weight': (1, 1),\n",
    "                'max_delta_weight': (1, 12),\n",
    "                'rate_drop': (0, 1)}\n",
    "    elif 'knn' in model_name : \n",
    "        return {'weight': (0, 1),\n",
    "                'algorithm' : (0, 3),\n",
    "                'leaf_size' : (5, 50),\n",
    "                'p': (1, 2),}\n",
    "    elif 'svm' in model_name : \n",
    "        return {'C': (0.01, 1), 'random_state' : (0, 5)}\n",
    "    elif 'lgbm' in model_name :\n",
    "        return {'min_child_weight': (0.01, 1),\n",
    "              'learning_rate': (1, 10),\n",
    "              'max_depth': (-1, 10),\n",
    "              'num_leaves': (5, 20)}\n",
    "\n",
    "def reset_model(model_name, params=None) :\n",
    "    if 'xgb' in model_name :\n",
    "        return XGBClassifier(**xgboost_params) if params is None else XGBClassifier(**params)\n",
    "    elif 'knn' in model_name :\n",
    "        return KNeighborsClassifier(**knn_params)\n",
    "    elif 'svm' in model_name :\n",
    "        return svm.LinearSVC(**svm_params) if params is None else svm.LinearSVC(**params)\n",
    "    else :\n",
    "        return LGBMClassifier(**lgbm_params) if params is None else LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = ['xgboost', 'lgbm', 'knn', 'svm']\n",
    "model_idx = 1\n",
    "model_name = model_name_list[model_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   booster |     gamma |   learning_rate |   max_delta_weight |   max_depth |   min_child_weight |   rate_drop | \n",
      "    1 | 00m04s | \u001b[35m   0.74681\u001b[0m | \u001b[32m   1.5671\u001b[0m | \u001b[32m   2.0326\u001b[0m | \u001b[32m         7.0588\u001b[0m | \u001b[32m            3.1128\u001b[0m | \u001b[32m     5.6152\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.2094\u001b[0m | \n",
      "    2 | 00m00s |    0.69945 |    2.3863 |    2.3447 |          8.7896 |             8.9824 |      7.6769 |             1.0000 |      0.7307 | \n",
      "    3 | 00m04s |    0.74317 |    1.8809 |    1.3462 |          4.2000 |             9.6343 |      5.3789 |             1.0000 |      0.6511 | \n",
      "    4 | 00m05s |    0.72896 |    1.3137 |    1.4590 |          6.6191 |            11.6931 |      7.0096 |             1.0000 |      0.4790 | \n",
      "    5 | 00m00s |    0.70747 |    2.0893 |    2.2884 |         10.8224 |            10.3607 |      5.2807 |             1.0000 |      0.2748 | \n",
      "    6 | 00m00s |    0.70783 |    2.5606 |    4.3027 |         10.8592 |             6.9795 |      6.1160 |             1.0000 |      0.6522 | \n",
      "    7 | 00m02s |    0.74499 |    1.6127 |    2.9313 |          2.3814 |             1.9877 |      3.4307 |             1.0000 |      0.9564 | \n",
      "    8 | 00m03s |    0.74681 |    1.4439 |    1.4174 |          3.2797 |             6.3776 |      4.6987 |             1.0000 |      0.4355 | \n",
      "    9 | 00m07s |    0.72058 |    1.7759 |    1.3899 |          1.5661 |            11.2073 |      9.8012 |             1.0000 |      0.0701 | \n",
      "   10 | 00m00s |    0.68051 |    2.8728 |    2.2731 |          5.8489 |             9.6638 |      4.6141 |             1.0000 |      0.0577 | \n",
      "   11 | 00m00s |    0.55811 |    2.9520 |    1.0271 |          1.3286 |             6.3360 |      7.8403 |             1.0000 |      0.0829 | \n",
      "   12 | 00m00s |    0.68087 |    2.3448 |    1.0069 |          6.0252 |             6.0081 |      7.5533 |             1.0000 |      0.9597 | \n",
      "   13 | 00m00s |    0.69727 |    2.8057 |    2.5702 |          8.1406 |             3.3978 |      8.0676 |             1.0000 |      0.5408 | \n",
      "   14 | 00m00s |    0.66120 |    2.6915 |    0.4361 |          4.0634 |             2.9493 |      6.3256 |             1.0000 |      0.8375 | \n",
      "   15 | 00m05s |    0.74281 |    1.7560 |    2.4179 |          8.4388 |             1.8099 |      7.1766 |             1.0000 |      0.1700 | \n",
      "   16 | 00m02s | \u001b[35m   0.75774\u001b[0m | \u001b[32m   1.1844\u001b[0m | \u001b[32m   1.8109\u001b[0m | \u001b[32m         7.4995\u001b[0m | \u001b[32m           10.8163\u001b[0m | \u001b[32m     3.4688\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.2603\u001b[0m | \n",
      "   17 | 00m00s |    0.55337 |    2.3068 |    3.5384 |          1.2638 |             8.0419 |      3.5079 |             1.0000 |      0.6920 | \n",
      "   18 | 00m00s |    0.68925 |    2.1157 |    3.7337 |          7.1474 |             2.5767 |      4.3928 |             1.0000 |      0.8956 | \n",
      "   19 | 00m03s |    0.75082 |    1.7231 |    3.4555 |          3.8518 |             5.5554 |      4.0630 |             1.0000 |      0.3407 | \n",
      "   20 | 00m02s |    0.75483 |    1.4501 |    3.4459 |          5.5661 |             1.5402 |      3.7007 |             1.0000 |      0.0647 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   booster |     gamma |   learning_rate |   max_delta_weight |   max_depth |   min_child_weight |   rate_drop | \n",
      "   21 | 00m16s |    0.74718 |    1.0000 |    5.0000 |          1.0000 |             1.0000 |     10.0000 |             1.0000 |      1.0000 | \n",
      "   22 | 00m17s |    0.75009 |    1.0000 |    5.0000 |         12.0000 |             1.0000 |     10.0000 |             1.0000 |      0.0000 | \n",
      "   23 | 00m18s |    0.75009 |    1.0000 |    5.0000 |         12.0000 |            12.0000 |     10.0000 |             1.0000 |      0.0000 | \n",
      "0.149\n",
      "0.248\n",
      "0.224\n",
      "0.215\n",
      "0.346\n",
      "0.344\n",
      "0.286\n",
      "0.344\n",
      "0.233\n",
      "0.145\n",
      "0.091\n",
      "0.182\n",
      "0.222\n",
      "0.271\n",
      "0.315\n",
      "0.298\n",
      "0.203\n",
      "0.205\n",
      "0.274\n",
      "0.218\n",
      "0.244\n",
      "0.250\n",
      "0.265\n",
      "0.244\n",
      "0.205\n",
      "0.284\n",
      "0.282\n",
      "0.227\n",
      "0.205\n",
      "0.177\n",
      "0.241\n",
      "0.195\n",
      "0.306\n"
     ]
    }
   ],
   "source": [
    "t = get_target(model_name, x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "xgbBO = BayesianOptimization(t.evaluate, \n",
    "                             get_params_range(model_name),\n",
    "                             random_state = random, \n",
    "                             verbose=1)\n",
    "\n",
    "xgbBO.maximize(init_points=20, n_iter=3)\n",
    "params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "model = reset_model(model_name, params=params)\n",
    "# model = reset_model(model_name)\n",
    "\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "for s in demo_config[6] :\n",
    "    y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(y_pci_test_dict[(p, s)], predictions)\n",
    "    nrmse_matrix[model_idx, 0, s] = err\n",
    "    \n",
    "pickle.dump(model, open(\"db/%s_%s_baseline.pickle.dat\" % ('PCI', model_name), \"wb\"))\n",
    "for x in nrmse_matrix[model_idx, 0, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.170\n",
      "0.327\n",
      "0.271\n",
      "0.215\n",
      "0.346\n",
      "0.389\n",
      "0.407\n",
      "0.378\n",
      "0.314\n",
      "0.303\n",
      "0.182\n",
      "0.195\n",
      "0.296\n",
      "0.329\n",
      "0.360\n",
      "0.333\n",
      "0.228\n",
      "0.178\n",
      "0.381\n",
      "0.256\n",
      "0.305\n",
      "0.238\n",
      "0.337\n",
      "0.293\n",
      "0.301\n",
      "0.321\n",
      "0.412\n",
      "0.227\n",
      "0.269\n",
      "0.228\n",
      "0.277\n",
      "0.208\n",
      "0.329\n"
     ]
    }
   ],
   "source": [
    "for s in demo_config[6] :\n",
    "    t = get_target(model_name, x_pci_train_dict[(6, s)], y_pci_train_dict[(6, s)], \n",
    "                   x_pci_test_dict[(6, s)], y_pci_test_dict[(6, s)])\n",
    "    xgbBO = BayesianOptimization(t.evaluate, \n",
    "                                 get_params_range(model_name),\n",
    "                                 random_state = random, \n",
    "                                 verbose=0)\n",
    "\n",
    "    xgbBO.maximize(init_points=20, n_iter=3)\n",
    "    params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "    \n",
    "    model = reset_model(model_name, params=params)\n",
    "    \n",
    "#     model = reset_model(model_name)\n",
    "    model.fit(x_pci_train_dict[(6, s)], y_pci_train_dict[(6, s)])\n",
    "\n",
    "    y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(y_pci_test_dict[(6, s)], predictions)\n",
    "    nrmse_matrix[model_idx, 1, s] = err\n",
    "    \n",
    "    pickle.dump(model, open(\"db/%s_%s_independent_set_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n",
    "\n",
    "for x in nrmse_matrix[model_idx, 1, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128\n",
      "0.212\n",
      "0.224\n",
      "0.190\n",
      "0.321\n",
      "0.400\n",
      "0.297\n",
      "0.333\n",
      "0.198\n",
      "0.132\n",
      "0.091\n",
      "0.208\n",
      "0.210\n",
      "0.247\n",
      "0.281\n",
      "0.250\n",
      "0.304\n",
      "0.260\n",
      "0.274\n",
      "0.154\n",
      "0.183\n",
      "0.238\n",
      "0.253\n",
      "0.207\n",
      "0.217\n",
      "0.235\n",
      "0.271\n",
      "0.280\n",
      "0.179\n",
      "0.152\n",
      "0.193\n",
      "0.208\n",
      "0.329\n"
     ]
    }
   ],
   "source": [
    "for s in demo_config[6] :\n",
    "    curr_x_pci_train = pci_data[pci_data.set!=s].drop(['PCI', 'set'], axis=1)\n",
    "    curr_y_pci_train = pci_data[pci_data.set!=s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    \n",
    "#     Testing 100%\n",
    "#     curr_x_pci_test = pci_data[pci_data.set==s].drop(['PCI', 'set'], axis=1)\n",
    "#     curr_y_pci_test = pci_data[pci_data.set==s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "#     Testing 30%\n",
    "    curr_x_pci_test = x_pci_test_dict[(6, s)]\n",
    "    curr_y_pci_test = y_pci_test_dict[(6, s)]\n",
    "    curr_x_pci_test = curr_x_pci_test.drop(['set'], axis=1)\n",
    "\n",
    "    t = get_target(model_name, curr_x_pci_train, curr_y_pci_train, curr_x_pci_test, curr_y_pci_test)\n",
    "    xgbBO = BayesianOptimization(t.evaluate, \n",
    "                                 get_params_range(model_name),\n",
    "                                 random_state = random, \n",
    "                                 verbose=0)\n",
    "\n",
    "    xgbBO.maximize(init_points=20, n_iter=3)\n",
    "    params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "    \n",
    "    model = reset_model(model_name, params=params)\n",
    "#     model = reset_model(model_name)\n",
    "\n",
    "    model.fit(curr_x_pci_train, curr_y_pci_train)\n",
    "\n",
    "    y_pred = model.predict(curr_x_pci_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(curr_y_pci_test, predictions)\n",
    "    nrmse_matrix[model_idx, 2, s] = err\n",
    "    print('%.3f' % err)\n",
    "    \n",
    "    pickle.dump(model, open(\"db/%s_%s_transfer_except_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n",
    "    \n",
    "# for x in nrmse_matrix[model_idx, 2, 1:]:\n",
    "#     print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n",
      "lgbm\n",
      "knn\n",
      "svm\n"
     ]
    }
   ],
   "source": [
    "random = 0\n",
    "for model_idx in range(0, 4) :\n",
    "    model_name = model_name_list[model_idx]\n",
    "    print(model_name)\n",
    "    \n",
    "#     Baseline\n",
    "    t = get_target(model_name, x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "    xgbBO = BayesianOptimization(t.evaluate, \n",
    "                                 get_params_range(model_name),\n",
    "                                 random_state = random, \n",
    "                                 verbose=0)\n",
    "\n",
    "    xgbBO.maximize(init_points=20, n_iter=3)\n",
    "    params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "    model = reset_model(model_name, params=params)\n",
    "    # model = reset_model(model_name)\n",
    "\n",
    "    model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "    for s in demo_config[6] :\n",
    "        y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        err = 1-accuracy_score(y_pci_test_dict[(p, s)], predictions)\n",
    "        nrmse_matrix[model_idx, 0, s] = err\n",
    "\n",
    "    pickle.dump(model, open(\"db/%s_%s_baseline.pickle.dat\" % ('PCI', model_name), \"wb\"))\n",
    "    \n",
    "# Independent\n",
    "    for s in demo_config[6] :\n",
    "        t = get_target(model_name, x_pci_train_dict[(6, s)], y_pci_train_dict[(6, s)], \n",
    "                       x_pci_test_dict[(6, s)], y_pci_test_dict[(6, s)])\n",
    "        xgbBO = BayesianOptimization(t.evaluate, \n",
    "                                     get_params_range(model_name),\n",
    "                                     random_state = random, \n",
    "                                     verbose=0)\n",
    "\n",
    "        xgbBO.maximize(init_points=20, n_iter=3)\n",
    "        params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "        model = reset_model(model_name, params=params)\n",
    "\n",
    "    #     model = reset_model(model_name)\n",
    "        model.fit(x_pci_train_dict[(6, s)], y_pci_train_dict[(6, s)])\n",
    "\n",
    "        y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        err = 1-accuracy_score(y_pci_test_dict[(6, s)], predictions)\n",
    "        nrmse_matrix[model_idx, 1, s] = err\n",
    "\n",
    "        pickle.dump(model, open(\"db/%s_%s_independent_set_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n",
    "\n",
    "# Transfer\n",
    "    for s in demo_config[6] :\n",
    "        curr_x_pci_train = pci_data[pci_data.set!=s].drop(['PCI', 'set'], axis=1)\n",
    "        curr_y_pci_train = pci_data[pci_data.set!=s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "\n",
    "    #     Testing 100%\n",
    "    #     curr_x_pci_test = pci_data[pci_data.set==s].drop(['PCI', 'set'], axis=1)\n",
    "    #     curr_y_pci_test = pci_data[pci_data.set==s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    #     Testing 30%\n",
    "        curr_x_pci_test = x_pci_test_dict[(6, s)]\n",
    "        curr_y_pci_test = y_pci_test_dict[(6, s)]\n",
    "        curr_x_pci_test = curr_x_pci_test.drop(['set'], axis=1)\n",
    "\n",
    "        t = get_target(model_name, curr_x_pci_train, curr_y_pci_train, curr_x_pci_test, curr_y_pci_test)\n",
    "        xgbBO = BayesianOptimization(t.evaluate, \n",
    "                                     get_params_range(model_name),\n",
    "                                     random_state = random, \n",
    "                                     verbose=0)\n",
    "\n",
    "        xgbBO.maximize(init_points=20, n_iter=3)\n",
    "        params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "        model = reset_model(model_name, params=params)\n",
    "    #     model = reset_model(model_name)\n",
    "\n",
    "        model.fit(curr_x_pci_train, curr_y_pci_train)\n",
    "\n",
    "        y_pred = model.predict(curr_x_pci_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        err = 1-accuracy_score(curr_y_pci_test, predictions)\n",
    "        nrmse_matrix[model_idx, 2, s] = err\n",
    "#         print('%.3f' % err)\n",
    "\n",
    "        pickle.dump(model, open(\"db/%s_%s_transfer_except_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================baseline\n",
      "avg of each methods ['0.244', '0.236', '0.306', '0.267']\n",
      "best performance (array([0, 1, 3]), array([16, 14,  3]))\n",
      "diff performance\n",
      "0.028\n",
      "0.019\n",
      "0.076\n",
      "0.042\n",
      "========================================independent\n",
      "avg of each methods ['0.266', '0.279', '0.295', '0.308']\n",
      "best performance (array([0, 1, 2, 3]), array([16,  9,  2,  6]))\n",
      "diff performance\n",
      "0.028\n",
      "0.042\n",
      "0.051\n",
      "0.078\n",
      "========================================transfer\n",
      "avg of each methods ['0.238', '0.231', '0.264', '0.237']\n",
      "best performance (array([0, 1, 3]), array([14,  9, 10]))\n",
      "diff performance\n",
      "0.040\n",
      "0.038\n",
      "0.052\n",
      "0.036\n"
     ]
    }
   ],
   "source": [
    "scenarios = ['baseline', 'independent', 'transfer']\n",
    "for scenario in range(3) :\n",
    "    print(\"========================================\"+scenarios[scenario])\n",
    "    baseline_metrics = nrmse_matrix[:, scenario, 1:]\n",
    "    baseline_metrics = baseline_metrics[~np.isnan(baseline_metrics)].reshape((4,len(sets)))\n",
    "    print('avg of each methods', [ '%.3f' % elem for elem in np.mean(baseline_metrics, axis=1)])\n",
    "    print('best performance', np.unique(np.argmin(baseline_metrics, axis=0), return_counts=True))\n",
    "    \n",
    "    print('diff performance')\n",
    "    min_list = np.min(baseline_metrics, axis=0)\n",
    "\n",
    "    for x in baseline_metrics :\n",
    "        diff = x-min_list\n",
    "        print('%.3f' % np.mean(diff[np.nonzero(diff)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================xgboost\n",
      "avg of each scenario ['0.244', '0.266', '0.238']\n",
      "best performance (array([0, 1, 2]), array([ 9,  8, 16]))\n",
      "[baseline]diff avg 0.006\n",
      "[baseline]+++++++increase 19 -0.027\n",
      "[baseline]-------decrease 10 0.034\n",
      "[independent]diff avg 0.028\n",
      "[independent]+++++++increase 24 -0.057\n",
      "[independent]-------decrease 8 0.055\n",
      "========================================lgbm\n",
      "avg of each scenario ['0.236', '0.279', '0.231']\n",
      "best performance (array([0, 1, 2]), array([12,  2, 19]))\n",
      "[baseline]diff avg 0.005\n",
      "[baseline]+++++++increase 20 -0.028\n",
      "[baseline]-------decrease 10 0.040\n",
      "[independent]diff avg 0.048\n",
      "[independent]+++++++increase 24 -0.077\n",
      "[independent]-------decrease 6 0.046\n",
      "========================================knn\n",
      "avg of each scenario ['0.306', '0.295', '0.264']\n",
      "best performance (array([0, 1, 2]), array([ 3,  9, 21]))\n",
      "[baseline]diff avg 0.042\n",
      "[baseline]+++++++increase 29 -0.049\n",
      "[baseline]-------decrease 2 0.019\n",
      "[independent]diff avg 0.031\n",
      "[independent]+++++++increase 24 -0.053\n",
      "[independent]-------decrease 8 0.033\n",
      "========================================svm\n",
      "avg of each scenario ['0.267', '0.308', '0.237']\n",
      "best performance (array([0, 1, 2]), array([ 9,  5, 19]))\n",
      "[baseline]diff avg 0.030\n",
      "[baseline]+++++++increase 23 -0.048\n",
      "[baseline]-------decrease 6 0.020\n",
      "[independent]diff avg 0.071\n",
      "[independent]+++++++increase 26 -0.093\n",
      "[independent]-------decrease 4 0.016\n"
     ]
    }
   ],
   "source": [
    "for curr_model in range(4) :\n",
    "    print(\"========================================\"+model_name_list[curr_model])\n",
    "    metrics = nrmse_matrix[curr_model, :, 1:]\n",
    "    metrics = metrics[~np.isnan(metrics)].reshape((3,len(sets)))\n",
    "    print('avg of each scenario', [ '%.3f' % elem for elem in np.mean(metrics, axis=1)])\n",
    "    print('best performance', np.unique(np.argmin(metrics, axis=0), return_counts=True))\n",
    "    \n",
    "    transfer_metrics = nrmse_matrix[curr_model, 2, 1:]\n",
    "    for i in range(2) :\n",
    "        curr_metrics = nrmse_matrix[curr_model, i, 1:]\n",
    "        print('[%s]diff avg %.3f' % (scenarios[i], \n",
    "                                        np.mean(curr_metrics - transfer_metrics)))\n",
    "        \n",
    "        improve_idx = transfer_metrics < curr_metrics\n",
    "        diff = transfer_metrics[improve_idx] - curr_metrics[improve_idx]\n",
    "        print('[%s]+++++++increase %d %.3f' % (scenarios[i], len(diff), np.mean(diff)))\n",
    "        \n",
    "        drop_idx = transfer_metrics > curr_metrics\n",
    "        diff = transfer_metrics[drop_idx] - curr_metrics[drop_idx]\n",
    "        print('[%s]-------decrease %d %.3f' % (scenarios[i], len(diff), np.mean(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(nrmse_matrix, 'nrmse_matrix_pci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.149\n",
      "0.239\n",
      "0.224\n",
      "0.215\n",
      "0.346\n",
      "0.322\n",
      "0.275\n",
      "0.333\n",
      "0.233\n",
      "0.145\n",
      "0.104\n",
      "0.169\n",
      "0.222\n",
      "0.271\n",
      "0.326\n",
      "0.298\n",
      "0.177\n",
      "0.205\n",
      "0.274\n",
      "0.205\n",
      "0.232\n",
      "0.238\n",
      "0.277\n",
      "0.232\n",
      "0.205\n",
      "0.259\n",
      "0.282\n",
      "0.227\n",
      "0.218\n",
      "0.177\n",
      "0.193\n",
      "0.195\n",
      "0.318\n"
     ]
    }
   ],
   "source": [
    "test = load_from_pickle('nrmse_matrix_pci')\n",
    "for x in test[1, 0, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.149\n",
      "0.239\n",
      "0.224\n",
      "0.215\n",
      "0.346\n",
      "0.322\n",
      "0.275\n",
      "0.333\n",
      "0.233\n",
      "0.145\n",
      "0.104\n",
      "0.169\n",
      "0.222\n",
      "0.271\n",
      "0.326\n",
      "0.298\n",
      "0.177\n",
      "0.205\n",
      "0.274\n",
      "0.205\n",
      "0.232\n",
      "0.238\n",
      "0.277\n",
      "0.232\n",
      "0.205\n",
      "0.259\n",
      "0.282\n",
      "0.227\n",
      "0.218\n",
      "0.177\n",
      "0.193\n",
      "0.195\n",
      "0.318\n"
     ]
    }
   ],
   "source": [
    "for x in nrmse_matrix[1, 0, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predicted Coordinate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cut = 50  \n",
    "y_cut = 100 \n",
    "\n",
    "old_origin_img = cv2.imread('../image/map.png',0)\n",
    "crop = old_origin_img[y_cut:318, x_cut:927]\n",
    "crop = cv2.cvtColor(crop, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "x_coord_list = []\n",
    "y_coord_list = []\n",
    "pci_list = []\n",
    "for lon in range(0, crop.shape[1]) :\n",
    "    for lat in range(0, crop.shape[0]) :\n",
    "        x_coord_list.append(x_cut + lon)\n",
    "        y_coord_list.append(y_cut + lat)\n",
    "        \n",
    "all_x_pci = pd.DataFrame({'location_x':x_coord_list, 'location_y':y_coord_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Opt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "loc_df = pci_data[['location_x', 'location_y', 'PCI']]\n",
    "def get_pci(x, y) :\n",
    "    distance = lambda d: math.hypot(abs(x-d[0]), abs(y-d[1]))\n",
    "    loc_df[\"d\"] = loc_df.apply(distance, axis=1)\n",
    "    return loc_df.loc[loc_df.d.idxmin()].PCI\n",
    "\n",
    "class target() :\n",
    "    def optimize(self, x, y) :\n",
    "        if self.bayes_opt is None or self.bayes_opt.X is None:\n",
    "            return 1000\n",
    "\n",
    "        bo = self.bayes_opt\n",
    "        bo.gp.fit(bo.X, bo.Y)\n",
    "        mu, sigma = bo.gp.predict(all_x_pci.values, return_std=True)\n",
    "        return -np.mean(sigma)\n",
    "\n",
    "def posterior(bo, x):\n",
    "    bo.gp.fit(bo.X, bo.Y)\n",
    "    mu, sigma = bo.gp.predict(x, return_std=True)\n",
    "    plot(sigma)\n",
    "    plt.show()\n",
    "    return mu, sigma\n",
    "\n",
    "def plot_gp(bo, x, curr_x_train, curr_y_train, set_val, model, show_sigma_map=False):\n",
    "    path = \"../results/predicted/pci/real_%s_set_%d.png\" % (model, set_val)\n",
    "    background = get_map_image()\n",
    "    p_color = [pci_decode[y] for y in curr_y_train]\n",
    "    p_color = [pci_color_dict[y] if y in pci_color_dict else (255, 255, 255) for y in p_color]\n",
    "    b = visualize(background, curr_x_train['location_x'].astype(int), curr_x_train['location_y'].astype(int), \n",
    "                  p_color, path, adjustment=True)\n",
    "\n",
    "    if show_sigma_map :\n",
    "        normalize_sigma = matplotlib.colors.Normalize(vmin=min(sigma), vmax=max(sigma))\n",
    "        mu_map = [cmap(normalize_sigma(value))[:3] for value in mu_sigma]\n",
    "        mu_map = [[int(x*255) for x in value] for value in mu_map]    \n",
    "        a=visualize_all_location_heatmap(a, x_coord_view, y_coord_view, mu_map, \n",
    "                                         cmap, normalize_sigma, filename=None,\n",
    "                                         size=1, figsize=(20,10), adjustment=False, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         x |         y | \n",
      "    1 | 00m00s | \u001b[35m1000.00000\u001b[0m | \u001b[32m 530.7606\u001b[0m | \u001b[32m 230.7997\u001b[0m | \n",
      "    2 | 00m00s |   -0.99999 |  676.5059 |  218.2397 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         x |         y | \n",
      "    3 | 00m00s |   -0.99998 |  689.4791 |  189.5332 | \n",
      "    4 | 00m00s |   -0.98814 |  530.4559 |  231.3546 | \n",
      "    5 | 00m00s |   -1.00000 |   72.7881 |  228.1264 | \n",
      "    6 | 00m00s |   -1.00000 |  617.4562 |  261.6594 | \n",
      "    7 | 00m00s |   -1.00000 |  837.4735 |  285.0548 | \n",
      "    8 | 00m00s |   -1.00000 |   61.4990 |  274.8175 | \n",
      "    9 | 00m00s |   -1.00000 |  702.4929 |  159.9914 | \n",
      "   10 | 00m00s |   -1.00000 |  463.5776 |  267.2542 | \n",
      "   11 | 00m00s |   -1.00000 |  645.7080 |  121.2919 | \n",
      "   12 | 00m00s |   -1.00000 |  270.6671 |  108.0514 | \n",
      "   13 | 00m00s |   -1.00000 |  110.9284 |  167.7725 | \n",
      "   14 | 00m00s |   -1.00000 |  308.4461 |  282.7718 | \n",
      "   15 | 00m00s |   -1.00000 |  227.0939 |  212.1294 | \n",
      "   16 | 00m01s |   -1.00000 |  502.8038 |  251.3136 | \n",
      "   17 | 00m01s |   -1.00000 |  247.5171 |  156.4329 | \n",
      "   18 | 00m01s |   -1.00000 |  181.5580 |  119.0955 | \n",
      "   19 | 00m01s |   -1.00000 |  902.5334 |  188.5634 | \n",
      "   20 | 00m01s |   -1.00000 |  827.5607 |  231.3748 | \n",
      "   21 | 00m01s |   -1.00000 |  277.4446 |  159.6463 | \n",
      "   22 | 00m01s |   -1.00000 |  281.9177 |  260.0387 | \n",
      "   23 | 00m01s |   -1.00000 |  548.1383 |  276.6246 | \n",
      "   24 | 00m01s |   -1.00000 |  844.3512 |  194.9138 | \n",
      "   25 | 00m01s |   -1.00000 |  315.8294 |  192.2693 | \n",
      "   26 | 00m01s |   -1.00000 |  265.8192 |  225.4146 | \n",
      "   27 | 00m01s |   -1.00000 |  692.5012 |  203.4942 | \n",
      "   28 | 00m01s |   -1.00000 |  852.4811 |  213.3534 | \n",
      "   29 | 00m01s |   -1.00000 |  664.1507 |  219.7384 | \n",
      "   30 | 00m01s |   -1.00000 |  617.5662 |  106.2562 | \n",
      "   31 | 00m01s |   -1.00000 |  676.7202 |  212.9029 | \n",
      "   32 | 00m01s |   -1.00000 |  269.0165 |  276.6607 | \n",
      "   33 | 00m01s |   -1.00000 |  356.0789 |  221.3204 | \n",
      "   34 | 00m01s |   -1.00000 |  359.5852 |  287.7578 | \n",
      "   35 | 00m01s |   -1.00000 |  578.0120 |  127.9233 | \n",
      "   36 | 00m01s |   -1.00000 |  887.7417 |  165.6719 | \n",
      "   37 | 00m02s |   -1.00000 |  233.4534 |  190.5862 | \n",
      "   38 | 00m02s |   -1.00000 |  671.7233 |  140.1695 | \n",
      "   39 | 00m02s |   -1.00000 |  423.3700 |  265.3524 | \n",
      "   40 | 00m02s |   -1.00000 |  494.9418 |  118.5452 | \n",
      "   41 | 00m02s |   -1.00000 |  611.5755 |  209.2295 | \n",
      "   42 | 00m02s |   -1.00000 |  719.2265 |  279.3810 | \n",
      "   43 | 00m02s |   -1.00000 |  391.1457 |  144.0620 | \n",
      "   44 | 00m02s |   -1.00000 |  210.4568 |  124.9910 | \n",
      "   45 | 00m02s |   -1.00000 |  428.3903 |  245.5580 | \n",
      "   46 | 00m02s |   -1.00000 |  142.9707 |  108.5818 | \n",
      "   47 | 00m02s |   -1.00000 |  920.7567 |  261.0028 | \n",
      "   48 | 00m02s |   -1.00000 |  311.2336 |  276.7443 | \n",
      "   49 | 00m02s |   -1.00000 |  598.6788 |  257.5743 | \n",
      "   50 | 00m02s |   -1.00000 |  103.6302 |  130.9076 | \n",
      "   51 | 00m02s |   -1.00000 |  449.5019 |  146.3874 | \n",
      "   52 | 00m02s |   -1.00000 |  181.3938 |  108.3729 | \n",
      "   53 | 00m02s |   -1.00000 |  212.4273 |  202.3042 | \n",
      "   54 | 00m02s |   -1.00000 |  510.8446 |  305.1171 | \n",
      "   55 | 00m02s |   -1.00000 |  841.6185 |  312.8242 | \n",
      "   56 | 00m02s |   -1.00000 |  446.1404 |  235.1433 | \n",
      "   57 | 00m03s |   -1.00000 |  907.2968 |  106.6759 | \n",
      "   58 | 00m03s |   -1.00000 |  783.6765 |  148.8299 | \n",
      "   59 | 00m03s |   -1.00000 |  495.3630 |  219.1404 | \n",
      "   60 | 00m03s |   -1.00000 |  511.1303 |  253.7994 | \n",
      "   61 | 00m03s |   -1.00000 |  283.8433 |  175.6382 | \n",
      "   62 | 00m03s |   -1.00000 |  778.3403 |  110.7464 | \n",
      "   63 | 00m03s |   -1.00000 |  600.8688 |  293.8175 | \n",
      "   64 | 00m03s |   -1.00000 |  553.1711 |  138.5394 | \n",
      "   65 | 00m03s |   -1.00000 |  470.9657 |  227.4169 | \n",
      "   66 | 00m03s |   -1.00000 |  519.9153 |  305.6816 | \n",
      "   67 | 00m03s |   -1.00000 |  212.4133 |  160.2944 | \n",
      "   68 | 00m03s |   -1.00000 |  699.6440 |  302.0829 | \n",
      "   69 | 00m03s |   -1.00000 |  478.0419 |  305.1917 | \n",
      "   70 | 00m03s |   -1.00000 |  920.9547 |  227.7244 | \n",
      "   71 | 00m03s |   -1.00000 |  611.4258 |  247.2325 | \n",
      "   72 | 00m03s |   -1.00000 |  255.7282 |  174.2263 | \n",
      "   73 | 00m03s |   -1.00000 |  225.6159 |  225.6578 | \n",
      "   74 | 00m03s |   -1.00000 |  810.1037 |  221.6425 | \n",
      "   75 | 00m03s |   -1.00000 |  390.2604 |  278.3444 | \n",
      "   76 | 00m03s |   -1.00000 |  338.9105 |  240.3280 | \n",
      "   77 | 00m04s |   -1.00000 |  499.6570 |  200.1829 | \n",
      "   78 | 00m04s |   -1.00000 |  725.6379 |  179.0822 | \n",
      "   79 | 00m04s |   -1.00000 |  695.6243 |  235.1864 | \n",
      "   80 | 00m04s |   -1.00000 |  881.5801 |  182.6931 | \n",
      "   81 | 00m04s |   -1.00000 |  648.0476 |  159.2279 | \n",
      "   82 | 00m04s |   -1.00000 |  626.1526 |  169.4558 | \n",
      "   83 | 00m04s |   -1.00000 |  841.8433 |  111.7767 | \n",
      "   84 | 00m04s |   -1.00000 |  626.2502 |  210.3260 | \n",
      "   85 | 00m04s |   -1.00000 |  397.9712 |  200.5159 | \n",
      "   86 | 00m04s |   -1.00000 |  636.1594 |  220.6765 | \n",
      "   87 | 00m04s |   -1.00000 |  765.7339 |  244.7184 | \n",
      "   88 | 00m04s |   -1.00000 |  887.6857 |  286.5184 | \n",
      "   89 | 00m04s |   -1.00000 |  415.5502 |  152.8420 | \n",
      "   90 | 00m04s |   -1.00000 |  532.3043 |  160.7845 | \n",
      "   91 | 00m04s |   -1.00000 |  238.2937 |  227.8067 | \n",
      "   92 | 00m04s |   -1.00000 |   63.5850 |  247.3568 | \n",
      "   93 | 00m04s |   -1.00000 |  186.5984 |  226.5609 | \n",
      "   94 | 00m04s |   -1.00000 |  145.6929 |  110.7599 | \n",
      "   95 | 00m04s |   -1.00000 |  799.4820 |  169.4183 | \n",
      "   96 | 00m05s |   -1.00000 |  241.2555 |  233.0000 | \n",
      "   97 | 00m05s |   -1.00000 |  411.2565 |  238.0072 | \n",
      "   98 | 00m05s |   -1.00000 |  416.7254 |  198.0468 | \n",
      "   99 | 00m05s |   -1.00000 |  614.4080 |  235.9260 | \n",
      "  100 | 00m05s |   -1.00000 |  307.0520 |  290.8992 | \n",
      "  101 | 00m05s |   -1.00000 |  122.5689 |  158.8872 | \n",
      "  102 | 00m05s |   -1.00000 |  211.8100 |  143.4171 | \n"
     ]
    }
   ],
   "source": [
    "random = 0\n",
    "t = target()\n",
    "bo2 = BayesianOptimization(t.optimize, {'x': (min(x_coord_list), max(x_coord_list)), \n",
    "                                        'y': (min(y_coord_list), max(y_coord_list))},\n",
    "                           random_state=random, \n",
    "                           verbose=1)\n",
    "t.bayes_opt = bo2\n",
    "\n",
    "iterations = 100\n",
    "gp_params = {\"alpha\": 1e-5, \"n_restarts_optimizer\": 3, 'random_state':random}\n",
    "bo2.maximize(init_points=2, n_iter=iterations, acq=\"ei\", xi=0.1, **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         x |         y | \n",
      "    1 | 00m00s | \u001b[35m1000.00000\u001b[0m | \u001b[32m 532.4990\u001b[0m | \u001b[32m 106.4831\u001b[0m | \n",
      "    2 | 00m00s |   -0.99999 |  670.3375 |  199.1328 | \n",
      "    3 | 00m00s |   -0.99998 |  304.8326 |  240.8643 | \n",
      "    4 | 00m00s |   -0.99998 |  497.4850 |  160.4317 | \n",
      "    5 | 00m00s |   -0.99997 |  832.2215 |  246.7473 | \n",
      "    6 | 00m00s |   -0.99996 |  835.1527 |  228.2172 | \n",
      "    7 | 00m00s |   -0.99968 |  160.0127 |  105.2041 | \n",
      "    8 | 00m00s |   -0.99965 |  231.5448 |  221.2713 | \n",
      "    9 | 00m00s |   -0.99968 |   95.0853 |  156.2578 | \n",
      "   10 | 00m00s |   -0.99346 |  436.1494 |  190.0770 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         x |         y | \n",
      "   11 | 00m00s |   -0.99915 |  191.6835 |  118.1789 | \n",
      "   12 | 00m00s |   -0.99907 |  685.8851 |  220.6383 | \n",
      "   13 | 00m00s |   -0.99898 |  759.7297 |  189.2084 | \n",
      "   14 | 00m00s |   -0.99890 |  689.5051 |  205.3176 | \n",
      "   15 | 00m00s |   -0.99879 |   74.1186 |  293.2435 | \n",
      "   16 | 00m00s |   -0.99870 |  284.0895 |  112.8271 | \n",
      "   17 | 00m00s |   -0.99861 |  124.0220 |  283.6385 | \n",
      "   18 | 00m00s |   -0.99853 |  907.3729 |  206.2395 | \n",
      "   19 | 00m00s |   -0.99844 |  525.9184 |  277.4743 | \n",
      "   20 | 00m00s |   -0.99835 |  889.5909 |  282.8063 | \n",
      "   21 | 00m00s |   -0.99827 |  642.3598 |  141.8439 | \n",
      "   22 | 00m00s |   -0.99818 |   83.1540 |  245.8494 | \n",
      "   23 | 00m00s |   -0.99809 |  146.9658 |  227.5656 | \n",
      "   24 | 00m00s |   -0.99801 |  849.4231 |  203.5465 | \n",
      "   25 | 00m00s |   -0.99792 |  911.0347 |  162.5082 | \n",
      "   26 | 00m00s |   -0.99783 |  721.3587 |  147.3591 | \n",
      "   27 | 00m00s |   -0.99775 |  749.2406 |  200.1970 | \n",
      "   28 | 00m00s |   -0.99761 |  231.8516 |  195.4195 | \n",
      "   29 | 00m00s |   -0.99752 |  311.4348 |  294.0007 | \n",
      "   30 | 00m00s |   -0.99743 |  655.4158 |  163.9583 | \n",
      "   31 | 00m00s |   -0.99734 |  229.9200 |  209.7774 | \n",
      "   32 | 00m00s |   -0.96681 |  756.8032 |  181.2018 | \n",
      "   33 | 00m00s |   -0.96518 |  285.9863 |  128.3427 | \n",
      "   34 | 00m00s |   -0.96360 |  217.3156 |  174.1325 | \n",
      "   35 | 00m00s |   -0.96212 |  260.0582 |  162.4782 | \n",
      "   36 | 00m00s |   -0.96078 |  651.3951 |  197.7339 | \n",
      "   37 | 00m00s |   -0.95915 |  501.9965 |  299.8920 | \n",
      "   38 | 00m00s |   -0.95778 |   95.0561 |  215.5687 | \n",
      "   39 | 00m00s |   -0.95630 |  663.7406 |  286.6141 | \n",
      "   40 | 00m00s |   -0.95507 |   61.6919 |  222.3986 | \n",
      "   41 | 00m00s |   -0.95360 |  512.8978 |  190.5508 | \n",
      "   42 | 00m00s |   -0.95208 |  255.5382 |  151.9782 | \n",
      "   43 | 00m00s |   -0.95053 |   92.1261 |  216.3475 | \n",
      "   44 | 00m00s |   -0.94916 |  733.2160 |  304.0027 | \n",
      "   45 | 00m00s |   -0.94793 |  497.1188 |  135.5287 | \n",
      "   46 | 00m00s |   -0.97357 |  316.4998 |  182.7692 | \n",
      "   47 | 00m00s |   -0.97296 |   86.4978 |  282.8888 | \n",
      "   48 | 00m00s |   -0.97202 |  192.0104 |  205.8806 | \n",
      "   49 | 00m00s |   -0.97137 |  750.5599 |  256.3746 | \n",
      "   50 | 00m00s |   -0.97074 |  216.8911 |  121.2432 | \n",
      "   51 | 00m00s |   -0.97000 |  835.2548 |  140.0805 | \n",
      "   52 | 00m00s |   -0.96937 |  274.9533 |  265.0504 | \n",
      "   53 | 00m00s |   -0.96873 |  876.0624 |  295.1737 | \n",
      "   54 | 00m00s |   -0.96784 |  417.3883 |  273.1587 | \n",
      "   55 | 00m00s |   -0.96721 |  440.5952 |  261.5004 | \n",
      "   56 | 00m00s |   -0.96647 |  248.9162 |  251.2742 | \n",
      "   57 | 00m00s |   -0.96574 |  409.3865 |  178.5090 | \n",
      "   58 | 00m00s |   -0.96503 |  377.7747 |  187.8222 | \n",
      "   59 | 00m00s |   -0.96435 |  375.4191 |  110.4182 | \n",
      "   60 | 00m00s |   -0.96370 |  585.1444 |  190.1304 | \n",
      "   61 | 00m01s |   -0.96309 |  701.0718 |  104.8664 | \n",
      "   62 | 00m01s |   -0.96256 |  759.1242 |  280.7684 | \n",
      "   63 | 00m01s |   -0.96177 |  328.4911 |  144.3942 | \n",
      "   64 | 00m01s |   -0.96111 |  883.3080 |  237.5175 | \n",
      "   65 | 00m01s |   -0.96044 |  491.9540 |  147.9798 | \n",
      "   66 | 00m01s |   -0.95897 |  534.4073 |  286.0300 | \n",
      "   67 | 00m01s |   -0.95801 |  533.1550 |  212.6669 | \n",
      "   68 | 00m01s |   -0.95728 |  143.9893 |  209.1733 | \n",
      "   69 | 00m01s |   -0.95638 |  730.9198 |  315.0574 | \n",
      "   70 | 00m01s |   -0.95567 |  644.8733 |  229.4002 | \n",
      "   71 | 00m01s |   -0.95494 |  292.0520 |  120.5361 | \n",
      "   72 | 00m01s |   -0.95404 |  542.6962 |  173.4419 | \n",
      "   73 | 00m01s |   -0.95338 |  342.9771 |  101.8397 | \n",
      "   74 | 00m01s |   -0.95288 |  215.7828 |  224.9887 | \n",
      "   75 | 00m01s |   -0.95196 |  517.2075 |  196.5765 | \n",
      "   76 | 00m01s |   -0.95102 |  861.0116 |  210.3016 | \n",
      "   77 | 00m01s |   -0.95009 |  510.0387 |  111.5782 | \n",
      "   78 | 00m01s |   -0.98942 |  368.4630 |  238.4604 | \n",
      "   79 | 00m01s |   -0.98928 |  645.8458 |  268.2455 | \n",
      "   80 | 00m01s |   -0.98914 |  486.6193 |  165.2299 | \n",
      "   81 | 00m01s |   -0.98888 |  644.0001 |  192.1354 | \n",
      "   82 | 00m01s |   -0.98855 |  122.6093 |  241.0418 | \n",
      "   83 | 00m01s |   -0.98840 |  663.7138 |  246.0285 | \n",
      "   84 | 00m01s |   -0.98826 |  811.7706 |  106.2098 | \n",
      "   85 | 00m01s |   -0.98812 |  426.2232 |  219.5537 | \n",
      "   86 | 00m01s |   -0.98798 |  844.8796 |  201.2502 | \n",
      "   87 | 00m01s |   -0.98751 |  684.7711 |  175.7316 | \n",
      "   88 | 00m01s |   -0.98736 |  566.4406 |  180.8487 | \n",
      "   89 | 00m01s |   -0.98721 |  827.2899 |  187.9669 | \n",
      "   90 | 00m01s |   -0.98706 |  560.0694 |  170.3406 | \n",
      "   91 | 00m01s |   -0.98681 |  576.3759 |  165.3672 | \n",
      "   92 | 00m01s |   -0.98663 |  360.0628 |  302.2642 | \n",
      "   93 | 00m01s |   -0.98648 |  445.5438 |  262.6068 | \n",
      "   94 | 00m01s |   -0.98607 |  354.2889 |  185.1578 | \n",
      "   95 | 00m01s |   -0.98591 |  259.8517 |  103.0827 | \n",
      "   96 | 00m01s |   -0.98577 |  147.3397 |  237.1105 | \n",
      "   97 | 00m01s |   -0.98547 |  139.5830 |  223.9289 | \n",
      "   98 | 00m01s |   -0.98513 |  283.8230 |  170.4229 | \n",
      "   99 | 00m01s |   -0.98497 |  622.7916 |  226.2942 | \n",
      "  100 | 00m01s |   -0.98481 |  764.1350 |  188.7496 | \n",
      "  101 | 00m01s |   -0.98441 |  530.8600 |  180.5537 | \n",
      "  102 | 00m01s |   -0.98420 |  216.6357 |  136.3772 | \n",
      "  103 | 00m01s |   -0.98401 |  409.4339 |  303.4001 | \n",
      "  104 | 00m01s |   -0.98385 |  344.9760 |  203.5822 | \n",
      "  105 | 00m01s |   -0.98368 |  851.5652 |  257.9327 | \n",
      "  106 | 00m01s |   -0.98352 |  543.5948 |  213.2682 | \n",
      "  107 | 00m01s |   -0.98325 |  615.2085 |  187.4384 | \n",
      "  108 | 00m01s |   -0.98309 |  247.9623 |  215.8179 | \n",
      "  109 | 00m01s |   -0.98290 |  894.5925 |  117.8490 | \n",
      "  110 | 00m01s |   -0.98274 |  117.1863 |  245.0445 | \n",
      "  111 | 00m01s |   -0.98239 |  557.6219 |  307.4152 | \n",
      "  112 | 00m01s |   -0.98223 |  353.9474 |  108.0158 | \n",
      "  113 | 00m01s |   -0.98200 |  662.1626 |  134.9888 | \n",
      "  114 | 00m01s |   -0.98183 |  638.9982 |  242.1302 | \n",
      "  115 | 00m01s |   -0.98162 |  345.8656 |  293.0092 | \n",
      "  116 | 00m01s |   -0.98144 |  155.9444 |  193.8375 | \n",
      "  117 | 00m01s |   -0.98126 |  589.2997 |  111.6608 | \n",
      "  118 | 00m01s |   -0.98110 |  557.4952 |  259.8858 | \n",
      "  119 | 00m01s |   -0.98093 |  908.9230 |  137.4798 | \n",
      "  120 | 00m01s |   -0.98077 |  803.9543 |  227.3395 | \n",
      "  121 | 00m01s |   -0.98060 |  318.5747 |  117.3801 | \n",
      "  122 | 00m01s |   -0.98043 |  612.2853 |  210.2826 | \n",
      "  123 | 00m01s |   -0.98026 |  246.4929 |  316.5783 | \n",
      "  124 | 00m01s |   -0.98015 |  178.5456 |  228.4153 | \n",
      "  125 | 00m01s |   -0.97999 |  399.6005 |  165.9413 | \n",
      "  126 | 00m01s |   -0.97979 |  883.8123 |  172.0285 | \n",
      "  127 | 00m01s |   -0.97963 |  153.5524 |  196.8877 | \n",
      "  128 | 00m01s |   -0.97922 |  316.0019 |  104.8101 | \n",
      "  129 | 00m01s |   -0.97900 |  386.8711 |  259.7484 | \n",
      "  130 | 00m01s |   -0.97883 |  427.1019 |  248.2228 | \n",
      "  131 | 00m02s |   -0.97865 |  443.9043 |  284.9992 | \n",
      "  132 | 00m02s |   -0.97848 |  426.6373 |  237.7902 | \n",
      "  133 | 00m02s |   -0.97819 |  506.7916 |  191.0823 | \n",
      "  134 | 00m02s |   -0.97785 |   89.1208 |  175.3921 | \n",
      "  135 | 00m02s |   -0.97768 |  725.1445 |  140.6776 | \n",
      "  136 | 00m02s |   -0.97736 |   61.7058 |  159.6764 | \n",
      "  137 | 00m02s |   -0.97718 |  225.1274 |  283.9099 | \n",
      "  138 | 00m02s |   -0.97701 |  240.8800 |  243.9970 | \n",
      "  139 | 00m02s |   -0.97675 |  636.9725 |  294.9668 | \n",
      "  140 | 00m02s |   -0.97657 |  108.0322 |  176.3042 | \n",
      "  141 | 00m02s |   -0.97639 |  688.5531 |  172.9391 | \n",
      "  142 | 00m02s |   -0.97603 |  754.6509 |  183.3705 | \n",
      "  143 | 00m02s |   -0.97567 |  718.0345 |  151.2096 | \n",
      "  144 | 00m02s |   -0.97538 |  512.7527 |  198.2929 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  145 | 00m02s |   -0.97503 |  376.5080 |  184.9413 | \n",
      "  146 | 00m02s |   -0.97472 |  704.1287 |  132.2572 | \n",
      "  147 | 00m02s |   -0.97453 |  819.5426 |  186.7378 | \n",
      "  148 | 00m02s |   -0.97424 |  459.8544 |  261.8791 | \n",
      "  149 | 00m02s |   -0.97403 |  698.4592 |  195.9000 | \n",
      "  150 | 00m02s |   -0.97380 |  211.1492 |  139.4483 | \n",
      "  151 | 00m02s |   -0.97350 |  539.5835 |  153.9385 | \n",
      "  152 | 00m02s |   -0.97331 |  355.3220 |  310.5848 | \n",
      "  153 | 00m02s |   -0.97304 |  634.3614 |  149.0565 | \n",
      "  154 | 00m02s |   -0.97278 |  913.7160 |  246.9051 | \n",
      "  155 | 00m02s |   -0.97260 |  715.7100 |  187.0292 | \n",
      "  156 | 00m02s |   -0.97241 |  921.6908 |  236.8554 | \n",
      "  157 | 00m02s |   -0.97218 |  751.2969 |  214.1380 | \n",
      "  158 | 00m02s |   -0.97196 |  619.0876 |  118.9626 | \n",
      "  159 | 00m02s |   -0.97177 |  368.4802 |  194.4183 | \n",
      "  160 | 00m02s |   -0.97151 |  816.7489 |  213.2403 | \n",
      "  161 | 00m02s |   -0.97131 |  764.0849 |  259.5815 | \n",
      "  162 | 00m02s |   -0.97109 |  285.6034 |  149.6087 | \n",
      "  163 | 00m02s |   -0.97089 |  339.2415 |  264.7321 | \n",
      "  164 | 00m03s |   -0.97070 |  687.0374 |  213.0409 | \n",
      "  165 | 00m03s |   -0.97036 |  729.8644 |  236.9324 | \n",
      "  166 | 00m03s |   -0.97017 |  741.5622 |  183.7100 | \n",
      "  167 | 00m02s |   -0.96994 |  336.4911 |  149.2030 | \n",
      "  168 | 00m02s |   -0.96966 |  762.3824 |  169.3246 | \n",
      "  169 | 00m02s |   -0.96944 |  787.2528 |  167.9259 | \n",
      "  170 | 00m02s |   -0.96925 |  694.5925 |  294.2594 | \n",
      "  171 | 00m02s |   -0.96906 |  216.6950 |  259.9121 | \n",
      "  172 | 00m02s |   -0.96887 |  104.9311 |  111.3492 | \n",
      "  173 | 00m02s |   -0.96868 |  253.9617 |  237.8770 | \n",
      "  174 | 00m02s |   -0.96843 |  582.5926 |  168.8953 | \n",
      "  175 | 00m02s |   -0.96813 |   55.8760 |  250.6992 | \n",
      "  176 | 00m03s |   -0.96795 |  450.0491 |  188.6245 | \n",
      "  177 | 00m03s |   -0.96772 |  921.7904 |  194.6781 | \n",
      "  178 | 00m03s |   -0.96753 |  544.7132 |  231.7275 | \n",
      "  179 | 00m03s |   -0.96732 |  809.8547 |  287.1615 | \n",
      "  180 | 00m03s |   -0.96713 |  505.5960 |  227.9271 | \n",
      "  181 | 00m02s |   -0.96694 |  727.7230 |  147.7664 | \n",
      "  182 | 00m03s |   -0.96664 |  177.7473 |  130.9395 | \n",
      "  183 | 00m03s |   -0.96644 |  354.2793 |  218.6382 | \n",
      "  184 | 00m03s |   -0.96623 |  353.5958 |  134.3289 | \n",
      "  185 | 00m03s |   -0.96603 |  738.7356 |  170.4805 | \n",
      "  186 | 00m03s |   -0.96580 |  175.3259 |  144.7487 | \n",
      "  187 | 00m03s |   -0.96557 |  905.6532 |  221.1428 | \n",
      "  188 | 00m03s |   -0.96534 |  555.9056 |  164.2576 | \n",
      "  189 | 00m03s |   -0.96504 |  174.2513 |  172.7322 | \n",
      "  190 | 00m03s |   -0.96485 |   62.7859 |  141.0459 | \n",
      "  191 | 00m03s |   -0.96464 |  321.6325 |  304.5095 | \n",
      "  192 | 00m03s |   -0.96442 |  344.6728 |  180.5574 | \n",
      "  193 | 00m03s |   -0.96415 |   77.7236 |  154.9458 | \n",
      "  194 | 00m03s |   -0.96391 |  610.4347 |  157.0419 | \n",
      "  195 | 00m03s |   -0.96371 |  160.3279 |  288.7549 | \n",
      "  196 | 00m03s |   -0.96352 |  320.7182 |  131.0890 | \n",
      "  197 | 00m03s |   -0.96327 |  642.4470 |  169.1369 | \n",
      "  198 | 00m03s |   -0.96302 |  272.0430 |  216.8668 | \n",
      "  199 | 00m03s |   -0.96282 |  116.3934 |  171.2119 | \n",
      "  200 | 00m03s |   -0.96255 |  886.1727 |  133.5814 | \n",
      "  201 | 00m03s |   -0.96233 |  845.6202 |  276.9508 | \n",
      "  202 | 00m03s |   -0.96213 |  834.9272 |  250.3612 | \n",
      "  203 | 00m03s |   -0.96183 |  474.7999 |  201.1346 | \n",
      "  204 | 00m03s |   -0.96163 |   85.1427 |  241.5683 | \n",
      "  205 | 00m03s |   -0.96134 |  351.4074 |  290.5215 | \n",
      "  206 | 00m03s |   -0.96102 |  495.0327 |  193.1511 | \n",
      "  207 | 00m03s |   -0.96077 |   67.9038 |  215.2341 | \n",
      "  208 | 00m03s |   -0.96050 |  366.2733 |  157.8637 | \n",
      "  209 | 00m03s |   -0.96030 |  251.9179 |  243.7725 | \n",
      "  210 | 00m03s |   -0.95998 |  367.9967 |  274.0880 | \n",
      "  211 | 00m03s |   -0.95976 |  125.7806 |  301.2081 | \n",
      "  212 | 00m03s |   -0.95955 |  254.2922 |  243.4981 | \n",
      "  213 | 00m03s |   -0.95927 |  256.4051 |  296.1207 | \n",
      "  214 | 00m03s |   -0.95906 |  741.3126 |  223.4048 | \n",
      "  215 | 00m03s |   -0.95881 |  373.2346 |  103.8596 | \n",
      "  216 | 00m03s |   -0.95854 |  713.9069 |  311.9328 | \n",
      "  217 | 00m03s |   -0.95833 |  452.6227 |  248.2554 | \n",
      "  218 | 00m03s |   -0.95808 |  340.5237 |  263.8756 | \n",
      "  219 | 00m03s |   -0.95780 |  168.4622 |  258.3634 | \n",
      "  220 | 00m03s |   -0.95760 |  490.8578 |  108.0033 | \n",
      "  221 | 00m03s |   -0.95736 |  130.3919 |  284.2723 | \n",
      "  222 | 00m03s |   -0.95707 |  284.7722 |  114.8994 | \n",
      "  223 | 00m03s |   -0.95680 |  671.9221 |  182.7982 | \n",
      "  224 | 00m03s |   -0.95656 |  618.3362 |  219.9534 | \n",
      "  225 | 00m04s |   -0.95623 |  545.2512 |  181.4261 | \n",
      "  226 | 00m04s |   -0.95594 |  300.1961 |  310.3023 | \n",
      "  227 | 00m04s |   -0.95573 |  245.0475 |  178.0250 | \n",
      "  228 | 00m04s |   -0.95551 |  675.6115 |  207.1785 | \n",
      "  229 | 00m04s |   -0.95521 |  882.2401 |  146.3588 | \n",
      "  230 | 00m06s |   -0.95495 |  412.1266 |  196.1272 | \n",
      "  231 | 00m05s |   -0.95473 |  503.9926 |  128.3813 | \n",
      "  232 | 00m04s |   -0.95445 |  460.9171 |  223.5890 | \n",
      "  233 | 00m04s |   -0.95424 |  284.0658 |  209.3736 | \n",
      "  234 | 00m04s |   -0.95399 |  502.4407 |  106.9551 | \n",
      "  235 | 00m04s |   -0.95349 |  656.1537 |  202.1530 | \n",
      "  236 | 00m04s |   -0.95321 |  497.2805 |  167.0019 | \n",
      "  237 | 00m04s |   -0.95292 |  518.9543 |  115.4569 | \n",
      "  238 | 00m04s |   -0.97814 |  747.4256 |  296.4122 | \n",
      "  239 | 00m04s |   -0.97805 |  853.5975 |  120.7891 | \n",
      "  240 | 00m04s |   -0.97795 |  122.0986 |  176.0336 | \n",
      "  241 | 00m04s |   -0.97780 |  421.4896 |  284.9395 | \n",
      "  242 | 00m04s |   -0.97770 |  688.4209 |  242.2349 | \n",
      "  243 | 00m04s |   -0.97760 |  427.3845 |  221.4588 | \n",
      "  244 | 00m04s |   -0.97741 |  754.0370 |  175.3686 | \n",
      "  245 | 00m04s |   -0.97724 |  904.6149 |  103.9080 | \n",
      "  246 | 00m04s |   -0.97715 |  162.1087 |  196.3555 | \n",
      "  247 | 00m04s |   -0.97699 |  784.0722 |  186.3419 | \n",
      "  248 | 00m04s |   -0.97690 |  903.0707 |  270.4899 | \n",
      "  249 | 00m04s |   -0.97680 |  244.2948 |  123.1518 | \n",
      "  250 | 00m04s |   -0.97671 |  155.4762 |  294.8588 | \n",
      "  251 | 00m04s |   -0.97656 |  127.5815 |  225.0621 | \n",
      "  252 | 00m04s |   -0.97645 |  269.4986 |  247.0780 | \n",
      "  253 | 00m04s |   -0.97635 |   75.8357 |  195.1931 | \n",
      "  254 | 00m05s |   -0.97625 |  645.2587 |  214.3024 | \n",
      "  255 | 00m05s |   -0.97615 |   94.7678 |  283.4499 | \n",
      "  256 | 00m05s |   -0.97602 |  165.9414 |  134.9214 | \n",
      "  257 | 00m05s |   -0.97591 |  705.2868 |  217.3161 | \n",
      "  258 | 00m05s |   -0.97581 |  103.5549 |  291.9866 | \n",
      "  259 | 00m05s |   -0.97571 |  522.3572 |  292.3050 | \n",
      "  260 | 00m05s |   -0.97560 |  453.7906 |  251.7301 | \n",
      "  261 | 00m05s |   -0.97540 |  755.3646 |  261.9221 | \n",
      "  262 | 00m05s |   -0.97523 |  915.6771 |  309.9855 | \n",
      "  263 | 00m06s |   -0.97513 |  237.5886 |  174.6235 | \n",
      "  264 | 00m05s |   -0.97499 |  264.4411 |  250.0126 | \n",
      "  265 | 00m05s |   -0.97482 |  569.4972 |  251.2392 | \n",
      "  266 | 00m05s |   -0.97471 |  423.5168 |  131.2252 | \n",
      "  267 | 00m05s |   -0.97462 |  361.8196 |  209.9102 | \n",
      "  268 | 00m05s |   -0.97450 |  638.2084 |  174.9016 | \n",
      "  269 | 00m05s |   -0.97435 |  492.6550 |  148.3948 | \n",
      "  270 | 00m05s |   -0.97416 |  727.4898 |  276.5510 | \n",
      "  271 | 00m06s |   -0.97406 |  439.7579 |  204.6389 | \n",
      "  272 | 00m06s |   -0.97396 |  534.9708 |  309.0037 | \n",
      "  273 | 00m06s |   -0.97386 |  501.6396 |  128.7891 | \n",
      "  274 | 00m06s |   -0.97367 |  917.0486 |  222.4728 | \n",
      "  275 | 00m05s |   -0.97355 |  710.3457 |  169.9961 | \n",
      "  276 | 00m05s |   -0.97345 |  216.6961 |  128.2088 | \n",
      "  277 | 00m05s |   -0.97327 |  109.3568 |  286.3618 | \n",
      "  278 | 00m05s |   -0.97312 |  417.6860 |  190.3764 | \n",
      "  279 | 00m05s |   -0.97298 |  553.5261 |  228.9004 | \n",
      "  280 | 00m06s |   -0.97285 |  245.2686 |  173.0933 | \n",
      "  281 | 00m05s |   -0.97267 |  580.3902 |  157.5529 | \n",
      "  282 | 00m05s |   -0.97254 |  108.6495 |  274.9157 | \n",
      "  283 | 00m05s |   -0.97242 |  740.8448 |  218.1183 | \n",
      "  284 | 00m06s |   -0.97225 |  504.7338 |  124.3673 | \n",
      "  285 | 00m05s |   -0.97208 |  198.4167 |  125.8569 | \n",
      "  286 | 00m06s |   -0.97196 |  341.0189 |  273.5504 | \n",
      "  287 | 00m06s |   -0.97182 |  793.0085 |  309.0965 | \n",
      "  288 | 00m06s |   -0.97172 |  923.8247 |  243.5763 | \n",
      "  289 | 00m06s |   -0.97157 |  107.4787 |  266.7557 | \n",
      "  290 | 00m07s |   -0.97143 |  421.9428 |  148.9861 | \n",
      "  291 | 00m06s |   -0.97133 |  504.7341 |  156.3231 | \n",
      "  292 | 00m06s |   -0.97119 |  743.6739 |  101.9470 | \n",
      "  293 | 00m06s |   -0.97110 |   93.6575 |  127.6818 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  294 | 00m06s |   -0.97100 |  906.1399 |  176.2233 | \n",
      "  295 | 00m06s |   -0.97090 |  648.9461 |  287.5102 | \n",
      "  296 | 00m06s |   -0.97078 |  760.2599 |  249.9943 | \n",
      "  297 | 00m06s |   -0.97065 |  876.3932 |  115.1651 | \n",
      "  298 | 00m06s |   -0.97054 |  666.4305 |  236.0795 | \n",
      "  299 | 00m06s |   -0.97042 |   59.1592 |  205.0674 | \n",
      "  300 | 00m06s |   -0.97031 |  757.7329 |  285.7268 | \n",
      "  301 | 00m06s |   -0.97015 |  894.6530 |  171.9127 | \n",
      "  302 | 00m06s |   -0.97002 |  199.6354 |  142.1749 | \n",
      "  303 | 00m06s |   -0.96990 |  172.4190 |  283.0682 | \n",
      "  304 | 00m06s |   -0.96979 |  380.6040 |  133.4013 | \n",
      "  305 | 00m06s |   -0.96969 |  823.2894 |  169.0986 | \n",
      "  306 | 00m07s |   -0.96959 |  278.5622 |  169.2848 | \n",
      "  307 | 00m07s |   -0.96942 |  696.0400 |  142.2999 | \n",
      "  308 | 00m08s |   -0.96931 |  819.5601 |  105.3234 | \n",
      "  309 | 00m06s |   -0.96917 |  729.6829 |  248.3993 | \n",
      "  310 | 00m07s |   -0.96905 |  807.0583 |  103.1906 | \n",
      "  311 | 00m07s |   -0.96890 |  787.5849 |  101.1791 | \n",
      "  312 | 00m07s |   -0.96882 |  713.6125 |  163.9389 | \n",
      "  313 | 00m06s |   -0.96867 |  680.8567 |  208.9762 | \n",
      "  314 | 00m06s |   -0.96848 |  444.2866 |  235.5268 | \n",
      "  315 | 00m06s |   -0.96837 |  331.3216 |  289.2377 | \n",
      "  316 | 00m07s |   -0.96826 |  188.4032 |  283.8812 | \n",
      "  317 | 00m06s |   -0.96815 |   69.0831 |  146.0473 | \n",
      "  318 | 00m07s |   -0.96800 |  812.9924 |  236.3616 | \n",
      "  319 | 00m07s |   -0.96789 |  894.1013 |  192.3647 | \n",
      "  320 | 00m07s |   -0.96778 |  702.6565 |  123.4271 | \n",
      "  321 | 00m07s |   -0.96765 |  568.8521 |  102.7416 | \n",
      "  322 | 00m07s |   -0.96755 |   94.6593 |  171.3788 | \n",
      "  323 | 00m07s |   -0.96739 |  171.2079 |  208.1343 | \n",
      "  324 | 00m07s |   -0.96728 |  923.5463 |  190.0369 | \n",
      "  325 | 00m07s |   -0.96713 |   92.2513 |  160.5910 | \n",
      "  326 | 00m07s |   -0.96696 |  389.3405 |  116.2231 | \n",
      "  327 | 00m07s |   -0.96685 |  495.9080 |  299.0981 | \n",
      "  328 | 00m07s |   -0.96670 |  875.6507 |  287.3744 | \n",
      "  329 | 00m07s |   -0.96655 |  892.5560 |  238.4535 | \n",
      "  330 | 00m07s |   -0.96642 |  262.2519 |  194.4693 | \n",
      "  331 | 00m07s |   -0.96631 |  471.3544 |  137.2023 | \n",
      "  332 | 00m08s |   -0.96621 |  582.1908 |  264.2861 | \n",
      "  333 | 00m07s |   -0.96610 |  902.7711 |  232.3811 | \n",
      "  334 | 00m07s |   -0.96597 |  379.4918 |  188.4596 | \n",
      "  335 | 00m07s |   -0.96580 |  145.7902 |  280.6483 | \n",
      "  336 | 00m08s |   -0.96569 |  290.2938 |  124.1876 | \n",
      "  337 | 00m09s |   -0.96551 |  250.3338 |  215.4896 | \n",
      "  338 | 00m07s |   -0.96535 |  494.4559 |  200.5292 | \n",
      "  339 | 00m08s |   -0.96521 |  214.6996 |  159.4349 | \n",
      "  340 | 00m08s |   -0.96510 |  519.1001 |  114.2212 | \n",
      "  341 | 00m09s |   -0.96939 |  779.6851 |  146.1318 | \n",
      "  342 | 00m08s |   -0.96929 |   58.6062 |  125.6028 | \n",
      "  343 | 00m08s |   -0.96920 |  109.4346 |  101.2813 | \n",
      "  344 | 00m08s |   -0.96911 |  385.3704 |  291.4506 | \n",
      "  345 | 00m08s |   -0.96902 |  426.9186 |  279.5452 | \n",
      "  346 | 00m08s |   -0.96889 |  670.3821 |  171.1062 | \n",
      "  347 | 00m08s |   -0.96878 |  131.1497 |  122.7254 | \n",
      "  348 | 00m09s |   -0.96869 |  736.8449 |  263.9738 | \n",
      "  349 | 00m09s |   -0.96859 |  535.3496 |  146.9283 | \n",
      "  350 | 00m09s |   -0.96847 |  855.5763 |  214.5426 | \n",
      "  351 | 00m09s |   -0.96834 |  406.4942 |  306.4113 | \n",
      "  352 | 00m09s |   -0.96820 |  666.6490 |  156.7094 | \n",
      "  353 | 00m08s |   -0.96810 |  674.4366 |  288.4272 | \n",
      "  354 | 00m09s |   -0.96799 |  339.3882 |  221.6362 | \n",
      "  355 | 00m08s |   -0.96790 |  375.3336 |  277.1805 | \n",
      "  356 | 00m09s |   -0.96777 |  595.9869 |  224.0952 | \n",
      "  357 | 00m09s |   -0.96768 |  403.9508 |  132.1125 | \n",
      "  358 | 00m10s |   -0.96759 |  779.3077 |  234.0313 | \n",
      "  359 | 00m09s |   -0.96749 |  418.2365 |  216.3183 | \n",
      "  360 | 00m10s |   -0.96738 |  804.5507 |  124.0092 | \n",
      "  361 | 00m08s |   -0.96728 |   76.0171 |  127.9422 | \n",
      "  362 | 00m09s |   -0.96719 |  243.8451 |  104.4803 | \n",
      "  363 | 00m08s |   -0.96709 |  688.3145 |  206.2967 | \n",
      "  364 | 00m09s |   -0.96695 |  840.1104 |  196.4325 | \n",
      "  365 | 00m08s |   -0.96682 |  250.2074 |  210.0143 | \n",
      "  366 | 00m09s |   -0.96669 |   91.9978 |  227.3171 | \n",
      "  367 | 00m08s |   -0.96658 |  842.2404 |  276.8002 | \n",
      "  368 | 00m09s |   -0.96644 |  231.5208 |  103.7738 | \n",
      "  369 | 00m09s |   -0.96634 |  740.4427 |  168.1825 | \n",
      "  370 | 00m09s |   -0.96621 |  398.8453 |  151.1940 | \n",
      "  371 | 00m11s |   -0.96611 |  141.9486 |  244.7360 | \n",
      "  372 | 00m09s |   -0.96599 |  367.9874 |  235.4907 | \n",
      "  373 | 00m09s |   -0.96586 |  242.1738 |  218.9725 | \n",
      "  374 | 00m10s |   -0.96572 |  498.4875 |  127.3292 | \n",
      "  375 | 00m09s |   -0.96557 |  536.1608 |  271.2118 | \n",
      "  376 | 00m10s |   -0.96547 |  567.5762 |  242.2358 | \n",
      "  377 | 00m09s |   -0.96535 |  364.9212 |  217.0040 | \n",
      "  378 | 00m12s |   -0.96522 |  741.7098 |  126.3897 | \n",
      "  379 | 00m09s |   -0.96512 |  159.2337 |  293.5227 | \n",
      "  380 | 00m11s |   -0.96498 |  473.7379 |  286.0861 | \n",
      "  381 | 00m09s |   -0.96488 |  398.8380 |  222.4113 | \n",
      "  382 | 00m09s |   -0.96478 |  278.6945 |  314.3966 | \n",
      "  383 | 00m09s |   -0.96470 |  381.8365 |  201.0319 | \n",
      "  384 | 00m10s |   -0.96459 |  606.9485 |  298.3906 | \n",
      "  385 | 00m10s |   -0.96450 |   95.6011 |  211.3850 | \n",
      "  386 | 00m10s |   -0.96436 |  825.5552 |  249.1197 | \n",
      "  387 | 00m10s |   -0.96423 |  617.9708 |  229.6530 | \n",
      "  388 | 00m10s |   -0.96410 |  337.3234 |  311.8294 | \n",
      "  389 | 00m10s |   -0.96400 |  149.3541 |  210.7257 | \n",
      "  390 | 00m11s |   -0.96386 |  485.2253 |  184.5217 | \n",
      "  391 | 00m11s |   -0.96376 |  381.8239 |  290.5800 | \n",
      "  392 | 00m11s |   -0.96362 |  537.4446 |  216.7084 | \n",
      "  393 | 00m10s |   -0.96347 |  870.0934 |  314.1909 | \n",
      "  394 | 00m11s |   -0.96338 |  515.7651 |  115.2614 | \n",
      "  395 | 00m11s |   -0.96337 |  309.2865 |  287.6693 | \n",
      "  396 | 00m11s |   -0.96324 |   55.4875 |  280.0719 | \n",
      "  397 | 00m11s |   -0.96314 |  137.2544 |  301.8543 | \n",
      "  398 | 00m11s |   -0.96303 |  392.7043 |  287.3437 | \n",
      "  399 | 00m11s |   -0.96292 |  612.8861 |  121.5088 | \n",
      "  400 | 00m11s |   -0.96279 |  347.8700 |  215.8019 | \n",
      "  401 | 00m11s |   -0.96265 |  688.3661 |  316.3798 | \n",
      "  402 | 00m11s |   -0.96258 |  768.3968 |  103.1468 | \n",
      "  403 | 00m14s |   -0.96249 |  159.0471 |  307.5852 | \n",
      "  404 | 00m11s |   -0.96239 |  798.7542 |  204.4881 | \n",
      "  405 | 00m11s |   -0.96229 |  902.1770 |  296.4850 | \n",
      "  406 | 00m11s |   -0.96219 |  139.4081 |  289.1276 | \n",
      "  407 | 00m11s |   -0.96207 |  235.5881 |  197.9962 | \n",
      "  408 | 00m11s |   -0.96193 |  337.5525 |  185.6757 | \n",
      "  409 | 00m12s |   -0.96181 |  731.0775 |  276.1690 | \n",
      "  410 | 00m13s |   -0.96168 |  809.5687 |  109.1671 | \n"
     ]
    }
   ],
   "source": [
    "random = 3\n",
    "t = target()\n",
    "bo3 = BayesianOptimization(t.optimize, {'x': (min(x_coord_list), max(x_coord_list)), \n",
    "                                        'y': (min(y_coord_list), max(y_coord_list))},\n",
    "                           random_state=random, \n",
    "                           verbose=1)\n",
    "t.bayes_opt = bo3\n",
    "\n",
    "iterations = 400\n",
    "gp_params = {\"alpha\": 1e-5, \"n_restarts_optimizer\": 3, 'random_state':random}\n",
    "bo3.maximize(init_points=10, n_iter=iterations, acq=\"ei\", xi=1e+1, **gp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2355212355212355\n",
      "0.32907348242811496\n",
      "0.3122362869198312\n",
      "0.31818181818181823\n",
      "0.3244444444444444\n",
      "0.4056224899598394\n",
      "0.4274509803921569\n",
      "0.4007936507936508\n",
      "0.37815126050420167\n",
      "0.23696682464454977\n",
      "0.2710280373831776\n",
      "0.2155963302752294\n",
      "0.3083700440528634\n",
      "0.38912133891213385\n",
      "0.3780487804878049\n",
      "0.3819742489270386\n",
      "0.2995391705069125\n",
      "0.25\n",
      "0.28755364806866957\n",
      "0.27188940092165903\n",
      "0.35398230088495575\n",
      "0.32432432432432434\n",
      "0.3318965517241379\n",
      "0.35398230088495575\n",
      "0.30603448275862066\n",
      "0.32173913043478264\n",
      "0.3620689655172413\n",
      "0.2932692307692307\n",
      "0.2844036697247706\n",
      "0.28959276018099545\n",
      "0.31759656652360513\n",
      "0.2990654205607477\n",
      "0.30932203389830504\n"
     ]
    }
   ],
   "source": [
    "acc_dict = {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.2*len(curr_pci_data)) + 5\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    temp3 = curr_pci_data[~curr_pci_data.index.isin(temp2.index)]\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    curr_x_test = temp3.drop(\"PCI\", axis=1)\n",
    "    curr_y_test = temp3.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "#     t = get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "#     xgbBO = BayesianOptimization(t.evaluate, \n",
    "#                                  get_params_range(model_name),\n",
    "#                                  random_state = random, \n",
    "#                                  verbose=0)\n",
    "\n",
    "#     xgbBO.maximize(init_points=5, n_iter=3)\n",
    "#     print(xgbBO.res['max']['max_params'])\n",
    "#     params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "    params = lgbm_params\n",
    "    params['min_data_in_bin']=1\n",
    "    params['min_data']=1\n",
    "    \n",
    "    model = reset_model(model_name, params)\n",
    "    model.fit(curr_x_train, curr_y_train)\n",
    "    pickle.dump(model, open(\"db/%s_%s_bayesian_independent_%s.pickle.dat\" % \\\n",
    "                            ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "# for set_val in demo_config[6] :\n",
    "    y_pci_pred = model.predict(curr_x_test)\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(curr_y_test, predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(curr_x_test), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934362934362934\n",
      "0.3482428115015974\n",
      "0.35443037974683544\n",
      "0.35\n",
      "0.4311111111111111\n",
      "0.48594377510040165\n",
      "0.4627450980392157\n",
      "0.503968253968254\n",
      "0.37914691943127965\n",
      "0.4299065420560748\n",
      "0.5154185022026432\n",
      "0.4518828451882845\n",
      "0.4796747967479674\n",
      "0.502145922746781\n",
      "0.3548387096774194\n",
      "0.3495575221238938\n",
      "0.36036036036036034\n",
      "0.44396551724137934\n",
      "0.4070796460176991\n",
      "0.43534482758620685\n",
      "0.5\n",
      "0.5043103448275862\n",
      "0.3557692307692307\n",
      "0.4862385321100917\n",
      "0.3846153846153846\n",
      "0.37768240343347637\n",
      "0.3271028037383178\n",
      "0.4491525423728814\n"
     ]
    }
   ],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_inden = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_inden[:, 2]) :\n",
    "    print(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   algorithm |   leaf_size |         p |    weight | \n",
      "    1 | 00m00s | \u001b[35m   0.58506\u001b[0m | \u001b[32m     2.6889\u001b[0m | \u001b[32m     6.3444\u001b[0m | \u001b[32m   1.5909\u001b[0m | \u001b[32m   0.5508\u001b[0m | \n",
      "    2 | 00m00s |    0.58506 |      0.3768 |     25.5575 |    1.0240 |    0.7081 | \n",
      "    3 | 00m00s |    0.58506 |      0.6217 |     34.2115 |    1.5589 |    0.2909 | \n",
      "    4 | 00m00s |    0.58506 |      0.1544 |     17.5319 |    1.2593 |    0.5108 | \n",
      "    5 | 00m00s |    0.58506 |      1.3224 |     35.4315 |    1.4151 |    0.8929 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   algorithm |   leaf_size |         p |    weight | \n",
      "    6 | 00m08s |    0.58506 |      2.7451 |     31.7164 |    1.5186 |    0.6827 | \n",
      "    7 | 00m06s |    0.58506 |      0.7536 |     29.4385 |    1.9309 |    0.6573 | \n",
      "    8 | 00m00s |    0.58506 |      0.4244 |     26.4909 |    1.7062 |    0.8789 | \n",
      "    9 | 00m02s |    0.58506 |      2.4474 |     23.2408 |    1.7117 |    0.0815 | \n",
      "   10 | 00m07s |    0.58506 |      0.5492 |     21.9880 |    1.9261 |    0.7905 | \n",
      "   11 | 00m09s |    0.58506 |      2.9776 |     25.3639 |    1.0517 |    0.3976 | \n",
      "   12 | 00m09s |    0.58506 |      0.8761 |     13.5423 |    1.0053 |    0.7873 | \n",
      "   13 | 00m06s |    0.58506 |      2.6054 |     25.6642 |    1.9176 |    0.6592 | \n",
      "   14 | 00m06s |    0.58506 |      1.3984 |     40.5720 |    1.0312 |    0.9461 | \n",
      "   15 | 00m07s |    0.58506 |      1.7966 |     30.3552 |    1.1673 |    0.6994 | \n",
      "   16 | 00m02s |    0.58506 |      1.3008 |     40.6010 |    1.2063 |    0.9036 | \n",
      "   17 | 00m04s |    0.58506 |      1.2359 |     36.9008 |    1.7362 |    0.7452 | \n",
      "   18 | 00m09s |    0.58506 |      1.4278 |     45.1488 |    1.4892 |    0.6265 | \n",
      "   19 | 00m09s |    0.58506 |      0.1716 |     46.1744 |    1.9148 |    0.3789 | \n",
      "   20 | 00m09s |    0.58506 |      1.9304 |     26.5910 |    1.4216 |    0.6863 | \n",
      "{'weight': 0.5507979025745755, 'algorithm': 2.6888792668003143, 'leaf_size': 6.3444294895355124, 'p': 1.5908628174163508}\n",
      "0.3916349809885932\n",
      "0.4668769716088328\n",
      "0.42148760330578516\n",
      "0.3973214285714286\n",
      "0.48245614035087714\n",
      "0.5375494071146245\n",
      "0.49224806201550386\n",
      "0.48046875\n",
      "0.4672897196261683\n",
      "0.45871559633027525\n",
      "0.4869565217391304\n",
      "0.4403292181069959\n",
      "0.4661354581673307\n",
      "0.5\n",
      "0.44545454545454544\n",
      "0.40174672489082974\n",
      "0.3733333333333333\n",
      "0.41276595744680855\n",
      "0.4217391304347826\n",
      "0.47457627118644063\n",
      "0.4678111587982833\n",
      "0.5021097046413502\n",
      "0.44131455399061037\n",
      "0.509009009009009\n",
      "0.45333333333333337\n",
      "0.4514767932489452\n",
      "0.46543778801843316\n",
      "0.41493775933609955\n"
     ]
    }
   ],
   "source": [
    "acc_dict = {}\n",
    "all_curr_x_train, all_curr_y_train = pd.DataFrame(), []\n",
    "all_curr_x_test, all_curr_y_test = pd.DataFrame(), []\n",
    "all_curr_x_test_dict, all_curr_y_test_dict = {}, {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.2*len(curr_pci_data))\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    temp3 = curr_pci_data[~curr_pci_data.index.isin(temp2.index)]\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    curr_x_test = temp3.drop(\"PCI\", axis=1)\n",
    "    curr_y_test = temp3.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "\n",
    "    all_curr_x_train = all_curr_x_train.append(curr_x_train)\n",
    "    all_curr_y_train += curr_y_train \n",
    "    all_curr_x_test = all_curr_x_test.append(curr_x_test)\n",
    "    all_curr_y_test += curr_y_test\n",
    "    all_curr_x_test_dict[set_val] = curr_x_test\n",
    "    all_curr_y_test_dict[set_val] = curr_y_test  \n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "t = get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "xgbBO = BayesianOptimization(t.evaluate, \n",
    "                             get_params_range(model_name),\n",
    "                             random_state = random, \n",
    "                             verbose=1)\n",
    "\n",
    "xgbBO.maximize(init_points=5, n_iter=15)\n",
    "print(xgbBO.res['max']['max_params'])\n",
    "params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "# params = lgbm_params\n",
    "params['min_data_in_bin']=1\n",
    "params['min_data']=1\n",
    "    \n",
    "model = reset_model(model_name, params)\n",
    "model.fit(curr_x_train, curr_y_train)\n",
    "pickle.dump(model, open(\"db/%s_%s_bayesian_baseline_%s.pickle.dat\" % ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "for set_val in demo_config[6] :\n",
    "    y_pci_pred = model.predict(all_curr_x_test_dict[set_val])\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(all_curr_y_test_dict[set_val], predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(curr_x_test), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3916349809885932\n",
      "0.4668769716088328\n",
      "0.42148760330578516\n",
      "0.3973214285714286\n",
      "0.48245614035087714\n",
      "0.5375494071146245\n",
      "0.49224806201550386\n",
      "0.48046875\n",
      "0.4672897196261683\n",
      "0.45871559633027525\n",
      "0.4869565217391304\n",
      "0.4403292181069959\n",
      "0.4661354581673307\n",
      "0.5\n",
      "0.44545454545454544\n",
      "0.40174672489082974\n",
      "0.3733333333333333\n",
      "0.41276595744680855\n",
      "0.4217391304347826\n",
      "0.47457627118644063\n",
      "0.4678111587982833\n",
      "0.5021097046413502\n",
      "0.44131455399061037\n",
      "0.509009009009009\n",
      "0.45333333333333337\n",
      "0.4514767932489452\n",
      "0.46543778801843316\n",
      "0.41493775933609955\n"
     ]
    }
   ],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_baseline = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_baseline[:, 2]) :\n",
    "    print(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.207667731629393\n",
      "0.2853333333333333\n",
      "0.27561837455830385\n",
      "0.24904214559386972\n",
      "0.3097014925373134\n",
      "0.37583892617449666\n",
      "0.32450331125827814\n",
      "0.3076923076923077\n",
      "0.19920318725099606\n",
      "0.2165354330708661\n",
      "0.25555555555555554\n",
      "0.2978723404255319\n",
      "0.3129251700680272\n",
      "0.3107142857142857\n",
      "0.2645914396887159\n",
      "0.2509225092250923\n",
      "0.21590909090909094\n",
      "0.25724637681159424\n",
      "0.2878228782287823\n",
      "0.30181818181818176\n",
      "0.28624535315985133\n",
      "0.3096085409252669\n",
      "0.2570281124497992\n",
      "0.2702702702702703\n",
      "0.2395437262357415\n",
      "0.2681159420289855\n",
      "0.2549019607843137\n",
      "0.28113879003558717\n"
     ]
    }
   ],
   "source": [
    "acc_dict = {}\n",
    "all_curr_x_train_dict, all_curr_y_train_dict = {}, {}\n",
    "all_curr_x_test_dict, all_curr_y_test_dict = {}, {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.7*len(curr_pci_data)) + 5\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    " \n",
    "    all_curr_x_train_dict[set_val] = curr_x_train\n",
    "    all_curr_y_train_dict[set_val] = curr_y_train  \n",
    "    all_curr_x_test_dict[set_val] = curr_pci_data.drop(\"PCI\", axis=1)\n",
    "    all_curr_y_test_dict[set_val] = curr_pci_data.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "#     print(set_val, len(curr_x_train), len(curr_x_test))\n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "#     t = get_target(model_name, all_curr_x_train, all_curr_y_train, all_curr_x_test, all_curr_y_test)\n",
    "#     xgbBO = BayesianOptimization(t.evaluate, \n",
    "#                                  get_params_range(model_name),\n",
    "#                                  random_state = random, \n",
    "#                                  verbose=0)\n",
    "\n",
    "#     xgbBO.maximize(init_points=5, n_iter=3)\n",
    "#     print(xgbBO.res['max']['max_params'])\n",
    "#     params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "    params = lgbm_params\n",
    "    params['min_data_in_bin']=1\n",
    "    params['min_data']=1\n",
    "    \n",
    "for set_val in demo_config[6] :\n",
    "    curr_x_train, curr_y_train = pd.DataFrame(), []\n",
    "    for k in all_curr_x_train_dict :\n",
    "        if k != set_val :\n",
    "            curr_x_train = curr_x_train.append(all_curr_x_train_dict[k])\n",
    "            curr_y_train += all_curr_y_train_dict[k]\n",
    "    \n",
    "    model = reset_model(model_name, params)\n",
    "    model.fit(curr_x_train, curr_y_train)\n",
    "    pickle.dump(model, open(\"db/%s_%s_bayesian_transfer_%s.pickle.dat\" % ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "    y_pci_pred = model.predict(all_curr_x_test_dict[set_val])\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(all_curr_y_test_dict[set_val], predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(all_curr_y_test_dict[set_val]), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.207667731629393\n",
      "0.2853333333333333\n",
      "0.27561837455830385\n",
      "0.24904214559386972\n",
      "0.3097014925373134\n",
      "0.37583892617449666\n",
      "0.32450331125827814\n",
      "0.3076923076923077\n",
      "0.19920318725099606\n",
      "0.2165354330708661\n",
      "0.25555555555555554\n",
      "0.2978723404255319\n",
      "0.3129251700680272\n",
      "0.3107142857142857\n",
      "0.2645914396887159\n",
      "0.2509225092250923\n",
      "0.21590909090909094\n",
      "0.25724637681159424\n",
      "0.2878228782287823\n",
      "0.30181818181818176\n",
      "0.28624535315985133\n",
      "0.3096085409252669\n",
      "0.2570281124497992\n",
      "0.2702702702702703\n",
      "0.2395437262357415\n",
      "0.2681159420289855\n",
      "0.2549019607843137\n",
      "0.28113879003558717\n"
     ]
    }
   ],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_transfer = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_transfer[:, 2]) :\n",
    "    print(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
