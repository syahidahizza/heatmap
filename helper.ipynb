{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import codecs\n",
    "import cv2\n",
    "import traceback\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "beam_list = [0, 32, 64, 96, 128]\n",
    "\n",
    "# for demo\n",
    "bs_location = {301:(868, 199), 302:(738, 206)}\n",
    "\n",
    "bs_location = {37:(902, 141), 38:(754, 149), 39:(249, 207),\n",
    "               40:(633, 209), 41:(482, 150), 42:(695, 271)}\n",
    "\n",
    "angle_dict = {-135:6, -90:5, -45:4, 0:3, 45:2, 90:1, 135:8, 180:7}\n",
    "\n",
    "# whitelist_PCI = [301, 302, 120, 151, 154]\n",
    "whitelist_PCI = [37, 38, 39, 40, 41, 42, 62]\n",
    "\n",
    "pci_encode = {k:v for k, v in zip(whitelist_PCI, range(0, len(whitelist_PCI)))}\n",
    "pci_decode = {pci_encode[k]: k for k in pci_encode}\n",
    "\n",
    "color_list = [\n",
    "    (0, 0, 255), #Blue\n",
    "    (0, 255, 0), #Green\n",
    "    (255, 0, 0), #Red\n",
    "    (135, 206, 250), #Sky Blue\n",
    "    (255, 165, 0), #orange     \n",
    "    (255, 160, 122), # salmon\n",
    "    (165, 42, 42) #Brown \n",
    "]\n",
    "\n",
    "pci_color_dict = {x:y for x, y in zip(whitelist_PCI, color_list[:len(whitelist_PCI)])}\n",
    "\n",
    "pci_color_dict_demo = {\n",
    "    301:(0, 0, 255), #Blue\n",
    "    302:(0, 255, 0), #Green\n",
    "    120:(255, 0, 0), #Red\n",
    "    151:(135, 206, 250), #Sky Blue\n",
    "    154:(165, 42, 42), #Brown \n",
    "} \n",
    "\n",
    "pci_color_dict_demo = {\n",
    "    448:(255, 255, 0), #Yellow\n",
    "    499:(160, 32, 240), #Purple\n",
    "    433:(255, 165, 0), #orange\n",
    "    447:(255, 20, 147), # deep pink\n",
    "    404:(255, 20, 147), # deep pink\n",
    "    41 : (218, 165, 32), # golden rod\n",
    "    1 : (255, 160, 122) # salmon\n",
    "} \n",
    "\n",
    "beam_map = {\n",
    "    0 : [0],\n",
    "    32 : [32],\n",
    "    64 : [64],\n",
    "    96 : [96],\n",
    "    128 : [128],\n",
    "    288 : [32, 64],\n",
    "    160 : [0, 32],\n",
    "    192 : [0, 64],\n",
    "    960 : [0, 32, 64, 96, 128]\n",
    "}\n",
    "\n",
    "set_detail_power = {\n",
    "    1:[{301:-10, 302:-10},\n",
    "       {301:-10, 302:-10},\n",
    "       {301:-10, 302:-10},\n",
    "       {301:-10, 302:-10},\n",
    "       {301:-9, 302:-10},\n",
    "       {301:-9, 302:-10},\n",
    "       {301:-9, 302:-10}],\n",
    "    2:[{301:-10, 302:-12},\n",
    "       {301:-10, 302:-12},\n",
    "       {301:-10, 302:-12},\n",
    "       {301:-9, 302:-12},\n",
    "       {301:-9, 302:-12},\n",
    "       {301:-9, 302:-12}],\n",
    "    3:[{301:-10, 302:-5},\n",
    "       {301:-10, 302:-5},\n",
    "       {301:-10, 302:-5},\n",
    "       {301:-10, 302:-5},\n",
    "       {301:-5, 302:-5},\n",
    "       {301:-5, 302:-5},\n",
    "       {301:-5, 302:-5}],\n",
    "    4:[{301:-10, 302:-10},\n",
    "       {301:-10, 302:0},\n",
    "       {301:-10, 302:-10},\n",
    "       {301:-10, 302:0}],\n",
    "    5:[{301:19, 302:19}, \n",
    "       {301:10, 302:10}],\n",
    "    \n",
    "    6:[{37:-2, 38:3, 39:0, 40:5, 41:-1, 42:15},\n",
    "       {37:18, 38:5, 39:3, 40:-1, 41:5, 42:14},\n",
    "       {37:-1, 38:20, 39:6, 40:2, 41:3, 42:15},\n",
    "       {37:10, 38:11, 39:1, 40:-3, 41:5, 42:14},\n",
    "       {37:-3, 38:-3, 39:10, 40:0, 41:-1, 42:20},\n",
    "       {37:13, 38:-3, 39:19, 40:7, 41:0, 42:9},\n",
    "      {37:-2, 38:13, 39:15, 40:-2, 41:2, 42:17},\n",
    "      {37:10, 38:9, 39:11, 40:-1, 41:0, 42:14},\n",
    "      {37:-4, 38:-2, 39:5, 40:8, 41:7, 42:17},\n",
    "      {37:14, 38:2, 39:-2, 40:13, 41:7, 42:15},\n",
    "      {37:1, 38:11, 39:1, 40:16, 41:3, 42:13},\n",
    "      {37:12, 38:20, 39:-5, 40:19, 41:6, 42:18},\n",
    "      {37:-4, 38:-2, 39:12, 40:16, 41:-4, 42:17},\n",
    "      {37:9, 38:3, 39:14, 40:18, 41:4, 42:19},\n",
    "      {37:6, 38:12, 39:17, 40:10, 41:-5, 42:17},\n",
    "      {37:14, 38:14, 39:19, 40:15, 41:3, 42:19},\n",
    "       {37:5, 38:2, 39:-3, 40:-2, 41:19, 42:8},\n",
    "      {37:14, 38:-3, 39:7, 40:4, 41:14, 42:14},\n",
    "       {37:-5, 38:16, 39:-5, 40:-5, 41:14, 42:9},\n",
    "       {37:18, 38:18, 39:4, 40:-4, 41:16, 42:14},\n",
    "       {37:7, 38:3, 39:18, 40:0, 41:13, 42:18},\n",
    "       {37:9, 38:-4, 39:10, 40:0, 41:18, 42:18},\n",
    "       {37:-5, 38:13, 39:14, 40:0, 41:16, 42:16},\n",
    "       {37:11, 38:13, 39:8, 40:7, 41:10, 42:9},\n",
    "       {37:-1, 38:-3, 39:1, 40:12, 41:20, 42:19},\n",
    "       {37:8, 38:4, 39:-2, 40:13, 41:15, 42:20},\n",
    "       {37:0, 38:20, 39:-2, 40:17, 41:16, 42:15},\n",
    "       {37:17, 38:16, 39:-3, 40:9, 41:20, 42:10},\n",
    "       {37:-5, 38:2, 39:19, 40:16, 41:10, 42:12},\n",
    "       {37:13, 38:7, 39:10, 40:19, 41:16, 42:12},\n",
    "       {37:-3, 38:13, 39:14, 40:9, 41:15, 42:10},\n",
    "       {37:13, 38:15, 39:11, 40:11, 41:16, 42:11},\n",
    "      {37:19, 38:19, 39:19, 40:19, 41:19, 42:19}]\n",
    "}\n",
    "                    \n",
    "set_detail_beam = {\n",
    "    1:[{301:0, 302:0},\n",
    "      {301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0},\n",
    "      {301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0}],\n",
    "   2:[{301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0},\n",
    "      {301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0}],\n",
    "    3:[{301:0, 302:0},\n",
    "      {301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0},\n",
    "      {301:32, 302:0},\n",
    "      {301:64, 302:0},\n",
    "      {301:288, 302:0}],\n",
    "    4:[{301:160, 302:0},\n",
    "       {301:160, 302:0},\n",
    "       {301:192, 302:0},\n",
    "       {301:192, 302:0}],\n",
    "    5:[{301:0, 302:0}, \n",
    "       {301:0, 302:0}],\n",
    "    6:[{37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "       {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960},\n",
    "        {37:960, 38:960, 39:960, 40:960, 41:960, 42:960}\n",
    "      ]\n",
    "}\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "\n",
    "def collect_df(paths) :\n",
    "    result = pd.DataFrame()\n",
    "    for path in paths :\n",
    "        for f in glob.glob(path) :\n",
    "            filename = f.split(\"/\")[-2:]\n",
    "            df = pd.DataFrame.from_csv(f)\n",
    "            df = df.reset_index()\n",
    "            df[\"setname\"] = filename[0] + \"/\" + filename[1] \n",
    "            result = pd.concat([result, df])\n",
    "    return result \n",
    "\n",
    "def get_source(priority, set_value) :\n",
    "     return '../data/demo-priority' + str(priority) + '/set' + str(set_value) + '/*'\n",
    "\n",
    "def extract_data_setting(path) :\n",
    "    set_df = pd.DataFrame()\n",
    "    for level_1_filename in glob.glob(path) :\n",
    "        nmf_file, mrk_file = None, None\n",
    "        for level_2_filename in glob.glob(level_1_filename + \"/*\") :\n",
    "            real_filename = level_2_filename.split(\"/\")[-1]\n",
    "\n",
    "            if \"mrk\" in real_filename :\n",
    "                mrk_file = level_2_filename            \n",
    "            if \"nmf\" in real_filename :\n",
    "                nmf_file = level_2_filename    \n",
    "            else :\n",
    "                for file in glob.glob(level_2_filename + \"/*\") :\n",
    "                    real_filename = file.split(\"/\")[-1]\n",
    "\n",
    "                    if \"mrk\" in real_filename :\n",
    "                        mrk_file = file            \n",
    "                    if \"nmf\" in real_filename :\n",
    "                        nmf_file = file\n",
    "\n",
    "        if mrk_file is not None and nmf_file is not None : \n",
    "            try :\n",
    "                df = extract_feature(mrk_file, nmf_file)\n",
    "                set_df = pd.concat([set_df, df])\n",
    "            except :\n",
    "                traceback.print_exc()\n",
    "        else :\n",
    "            print(level_1_filename, \"mrk found\", mrk_file is not None, \"nmf found\", nmf_file is not None)\n",
    "\n",
    "    # reorder the columns\n",
    "    return set_df[[\"location_x\", \"location_y\", \"PCI\", \"RSRP\", \"RSRQ\", \"SNR\", \"timestamp\", \"filename\"]]\n",
    "\n",
    "def extract_data_directly(config, feature=True, pure=False) :\n",
    "    result = pd.DataFrame()\n",
    "    for priority in config :\n",
    "        for set_value in config[priority] :\n",
    "            try :\n",
    "                set_df = extract_data_setting(get_source(priority, set_value))\n",
    "                if feature :\n",
    "                    if not pure :\n",
    "                        set_df = add_features_summary(set_df, priority, set_value)\n",
    "                    else :\n",
    "                        set_df = add_features(set_df, priority, set_value)\n",
    "                        set_df[\"priority\"] = priority\n",
    "                        set_df[\"set\"] = set_value\n",
    "\n",
    "                result = pd.concat([result, set_df])\n",
    "            except :\n",
    "                print(priority, set_value)\n",
    "                traceback.print_exc()\n",
    "                return df \n",
    "            \n",
    "    if pure :\n",
    "        result = result.drop([\"timestamp\", \"filename\"], axis=1)\n",
    "        result[\"PCI\"] = result[\"PCI\"].astype('int32')\n",
    "    return result\n",
    "\n",
    "def get_filenames(path) :\n",
    "    mrk_filenames = []\n",
    "    nmf_filenames = []\n",
    "    for level_1_filename in glob.glob(path) :\n",
    "        for level_2_filename in glob.glob(level_1_filename + \"/*\") :\n",
    "            real_filename = level_2_filename.split(\"/\")[-1]\n",
    "        \n",
    "            if \"mrk\" in real_filename :\n",
    "                mrk_filenames.append(level_2_filename)            \n",
    "            if \"nmf\" in real_filename :\n",
    "                nmf_filenames.append(level_2_filename)    \n",
    "            else :\n",
    "                for file in glob.glob(level_2_filename + \"/*\") :\n",
    "                    real_filename = file.split(\"/\")[-1]\n",
    "\n",
    "                    if \"mrk\" in real_filename :\n",
    "                        mrk_filenames.append(file)            \n",
    "                    if \"nmf\" in real_filename :\n",
    "                        nmf_filenames.append(file)            \n",
    "    \n",
    "    return mrk_filenames, nmf_filenames\n",
    "\n",
    "def extract_mrk(f) :\n",
    "    file = codecs.open(f, 'r', 'utf-8')\n",
    "    \n",
    "    lat = 0\n",
    "    lon = 0\n",
    "    for line in file :\n",
    "        if \"lat\" in line :\n",
    "            lat = float(line.strip().split(\"=\")[1])\n",
    "        if \"lon\" in line :\n",
    "            lon = float(line.strip().split(\"=\")[1])\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def extract_nmf(f) :\n",
    "    result = []\n",
    "    ci_lines = []\n",
    "    cellmeas_lines = []\n",
    "    file = codecs.open(f, 'r', 'utf-8')\n",
    "    readable = False\n",
    "    \n",
    "    for line in file :\n",
    "        try :\n",
    "            if \"START\" in line :\n",
    "                readable = True\n",
    "            \n",
    "            if \"CI,\" in line :\n",
    "                readable = True\n",
    "                line = line.strip()\n",
    "                lines = line.split(\",\")\n",
    "                SNR = float(lines[5])\n",
    "                ci = [lines[1], SNR]\n",
    "                ci_lines.append(ci)\n",
    "\n",
    "            if \"CELLMEAS\" in line :\n",
    "                readable = True\n",
    "                line = line.strip()\n",
    "                lines = line.split(\",\")[1:]\n",
    "\n",
    "                try :\n",
    "                    val = float(lines[11])\n",
    "                    cellmeas_lines.append(lines)\n",
    "                except :\n",
    "                    # failed to cast column[11] means it got weak signal\n",
    "                    # continue to process next line\n",
    "                    pass\n",
    "                \n",
    "        except :\n",
    "            traceback.print_exc()\n",
    "                        \n",
    "    df = pd.DataFrame(cellmeas_lines)\n",
    "\n",
    "    if not readable :\n",
    "        print(\"not readable file \" + f)\n",
    "        return df\n",
    "    \n",
    "    if len(cellmeas_lines) == 0 :\n",
    "        print(\"RSRP not found \" + f)\n",
    "        return df\n",
    "    \n",
    "    df = df.filter(items=[0, 9, 11, 12])    \n",
    "    df = df.rename(columns={0:\"timestamp\", 9:\"PCI\", 11:\"RSRP\", 12:\"RSRQ\"})\n",
    "\n",
    "    try :\n",
    "        df = df[df[\"PCI\"] != \"\"]\n",
    "        df['PCI'] = df['PCI'].apply(lambda x:int(x) if x != \"\" else float('nan'))\n",
    "        df['RSRP'] = df['RSRP'].apply(lambda x:float(x) if x != \"\" else float('nan'))\n",
    "        df['RSRQ'] = df['RSRQ'].apply(lambda x:float(x) if x != \"\" else float('nan'))\n",
    "    except :\n",
    "        print(\"failed to parse RSRP\")\n",
    "        return df\n",
    "\n",
    "    if len(ci_lines) == 0 :\n",
    "#         print(\"SNR not found in \" + f)\n",
    "        return df\n",
    "\n",
    "    SNR_df = pd.DataFrame(ci_lines)\n",
    "    SNR_df = SNR_df.rename(columns={0:\"timestamp\", 1:\"SNR\"})\n",
    "    df = pd.merge(df, SNR_df, on='timestamp')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# extract feature from both mrk and nmf file\n",
    "def extract_feature(mrk, nmf) :\n",
    "    lat, lon = extract_mrk(mrk)\n",
    "    \n",
    "    if lat == 0 and lon == 0 :\n",
    "        return\n",
    "    \n",
    "    df = extract_nmf(nmf)\n",
    "    df[\"location_y\"] = lat\n",
    "    df[\"location_x\"] = lon\n",
    "    \n",
    "    df['filename'] = mrk.split(\"/\")[-1]\n",
    "    return df\n",
    "\n",
    "def summary_based_on_location(lat_list, lon_list, data_list) :\n",
    "    summary = {}\n",
    "    for lat, lon, val in zip(lat_list, lon_list, data_list) :\n",
    "        if math.isnan(val) :\n",
    "            continue\n",
    "         \n",
    "        if lat not in summary :\n",
    "            summary[lat] = {}\n",
    "\n",
    "        summary_lat = summary[lat]\n",
    "        if lon not in summary_lat :\n",
    "            summary_lat[lon] = [val]\n",
    "        else :\n",
    "            summary_lat[lon].append(val)\n",
    "    return summary\n",
    "\n",
    "def summary_dict(data_dict, func) :\n",
    "    summary = {}\n",
    "    for lat in data_dict :\n",
    "        summary[lat] = {}\n",
    "        for lon in data_dict[lat] :\n",
    "            val = data_dict[lat][lon]\n",
    "            summary[lat][lon] = func(val)\n",
    "    return summary\n",
    "\n",
    "def summary_dict_to_list(data_dict) :\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for lat in data_dict :\n",
    "        for lon in data_dict[lat] :\n",
    "            val = data_dict[lat][lon]\n",
    "            x.append(lon)\n",
    "            y.append(lat)\n",
    "            z.append(val)\n",
    "    return np.array(x), np.array(y), np.array(z)\n",
    "\n",
    "# transform lat and long from NEMO background to new background\n",
    "# we need to crop old background from (50, 100) then  \n",
    "# old background shape : (218, 877)\n",
    "# new background shape : (234, 945)\n",
    "def transform_lat_lng(lat, lon) :\n",
    "    new_lat = (lat-100) * (945/877)\n",
    "    new_lng = (lon-50) * (234/218)\n",
    "\n",
    "    return int(new_lat), int(new_lng)\n",
    "\n",
    "def add_power(df, priority, set_value) :\n",
    "    if priority not in set_detail_power or set_value > len(set_detail_power[priority]) :\n",
    "        print(\"power configuration for this set haven't been listed\")\n",
    "        return df\n",
    "    \n",
    "    power_val = set_detail_power[priority][set_value-1] \n",
    "    for p in power_val :\n",
    "        df[\"Power_\" + str(p)] = power_val[p]\n",
    "    return df\n",
    "    \n",
    "def add_beam(df, priority, set_value) :\n",
    "    if priority not in set_detail_beam or set_value > len(set_detail_beam[priority]) :\n",
    "        print(\"beam configuration for this set haven't been listed\")\n",
    "        return df\n",
    "    \n",
    "    beam_val = set_detail_beam[priority][set_value-1] \n",
    "    for cell in beam_val :\n",
    "        value = beam_val[cell]\n",
    "        beam_map_val = beam_map[value]\n",
    "        for b in beam_list :\n",
    "            name = \"%d_beam%d\" % (cell, b)\n",
    "            df[name] = 1 if b in beam_map_val else 0\n",
    "    return df\n",
    "\n",
    "def add_distance(df) :\n",
    "    for bs in bs_location :\n",
    "        x, y = bs_location[bs]\n",
    "        distance = lambda d: math.hypot(abs(x-d[0]), abs(y-d[1]))\n",
    "        df[\"Distance_\" + str(bs)] = df.apply(distance, axis=1)\n",
    "    return df\n",
    "    \n",
    "def find_angle(diff_x, diff_y) :\n",
    "    radian = math.atan2(diff_x, diff_y)\n",
    "    degree = math.degrees(radian)\n",
    "    return degree\n",
    "\n",
    "def add_angle(df) :\n",
    "    for bs in bs_location :\n",
    "        x, y = bs_location[bs]\n",
    "        angle_func = lambda d: find_angle(x-d[0], y-d[1])\n",
    "        df[\"Angle_\" + str(bs)] = df.apply(angle_func, axis=1)\n",
    "    return df\n",
    "\n",
    "def map_angle(degree) :\n",
    "    for a in angle_dict :\n",
    "        if a >= degree :\n",
    "            return angle_dict[a]\n",
    "\n",
    "def add_angle_map(df) :\n",
    "    for bs in bs_location :\n",
    "        x, y = bs_location[bs]\n",
    "        angle_func = lambda d: map_angle(find_angle(x-d[0], y-d[1]))\n",
    "        df[\"Angle_\" + str(bs)] = df.apply(angle_func, axis=1)\n",
    "    return df\n",
    "\n",
    "def add_features(df, priority, set_value) :\n",
    "    df = add_power(df, priority, set_value)\n",
    "    df = add_beam(df, priority, set_value)\n",
    "    df = add_distance(df)\n",
    "    df = add_angle(df)\n",
    "    return df\n",
    "    \n",
    "def add_features_summary(df, priority, set_value) :\n",
    "    df = add_power(df, priority, set_value)\n",
    "    df = add_beam(df, priority, set_value)\n",
    "    df = add_distance(df)\n",
    "    df = add_angle_map(df)\n",
    "    return df\n",
    "\n",
    "def draw_base_station(source, adjustment=True) :\n",
    "    for bs in bs_location :\n",
    "        x, y = bs_location[bs]\n",
    "        \n",
    "        if adjustment :\n",
    "            y, x = transform_lat_lng(y, x)\n",
    "        \n",
    "        d = 10\n",
    "        top_left = (x-d, y+d)\n",
    "        bottom_right = (x+d, y-d)\n",
    "        source = cv2.rectangle(source, top_left, bottom_right, (160, 32, 240), -1)\n",
    "    return source\n",
    "\n",
    "def get_map_image(station=True, new_format=True) :\n",
    "    new_origin_img = cv2.imread('../image/5F.png') if new_format else cv2.imread('../image/map.png')\n",
    "    new_backtorgb = cv2.cvtColor(new_origin_img, cv2.COLOR_BGR2RGB)\n",
    "    new_backtorgb = draw_base_station(new_backtorgb, new_format)\n",
    "    return new_backtorgb\n",
    "\n",
    "def visualize(source, x_list, y_list, color, filename=None, size=4, figsize=(18,5), adjustment=True) :\n",
    "    for lon, lat, c in zip(x_list, y_list, color):\n",
    "        if adjustment :\n",
    "            lat, lon = transform_lat_lng(lat, lon)\n",
    "        source = cv2.circle(source, (lon, lat), size, c, -1)\n",
    "        \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(source, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "    \n",
    "    if filename != None :\n",
    "        fig.savefig(filename)\n",
    "        \n",
    "    return source\n",
    "\n",
    "def visualize_pci_heatmap(background, x_coord_list, y_coord_list, pci_pred, filename, figsize=(18,5), size=3) :\n",
    "    background = np.array(background)\n",
    "    heatmap = np.array(background)\n",
    "    for lon, lat, pci_code in zip(x_coord_list, y_coord_list, pci_pred) :\n",
    "        pci = pci_decode[pci_code]\n",
    "        colour = pci_color_dict[pci]\n",
    "        heatmap = cv2.circle(heatmap, (lon, lat), 3, colour, -1)\n",
    "\n",
    "    alpha = 0.7\n",
    "    final = cv2.addWeighted(background, alpha, heatmap, 1 - alpha, alpha)\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.imshow(final, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "    \n",
    "    if filename != None :\n",
    "        bgr = cv2.cvtColor(final, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(filename, bgr)\n",
    "        \n",
    "    return final \n",
    "\n",
    "def visualize_cmap(source, x_list, y_list, color, cmap, normalize, filename=None, \n",
    "                   size=4, figsize=(18,10), adjustment=True) :\n",
    "    \n",
    "    for lon, lat, c in zip(x_list, y_list, color):\n",
    "        if adjustment :\n",
    "            lat, lon = transform_lat_lng(lat, lon)\n",
    "        source = cv2.circle(source, (lon, lat), size, c, -1)\n",
    "        \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    columns = 1\n",
    "    rows = 2\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(source)\n",
    "    \n",
    "    \n",
    "    ax1 = fig.add_subplot(7, columns, 5)\n",
    "    cb1 = matplotlib.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                    norm=normalize,\n",
    "                                    orientation='horizontal')\n",
    "    plt.show()\n",
    "\n",
    "    if filename != None :\n",
    "        fig.savefig(filename)\n",
    "        \n",
    "    return source\n",
    "\n",
    "def visualize_all_location_heatmap(background, x_list, y_list, color, cmap, normalize, filename=None, \n",
    "                                   size=4, figsize=(18,10), adjustment=True, show=True) :\n",
    "    background = np.array(background)\n",
    "    heatmap = np.array(background)\n",
    "    for lon, lat, c in zip(x_list, y_list, color):\n",
    "        if adjustment :\n",
    "            lat, lon = transform_lat_lng(lat, lon)\n",
    "        heatmap = cv2.circle(heatmap, (lon, lat), size, c, -1)\n",
    "        \n",
    "    alpha = 0.7\n",
    "    final = cv2.addWeighted(background, alpha, heatmap, 1 - alpha, alpha)\n",
    "    \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    columns = 1\n",
    "    rows = 2\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(final)\n",
    "    \n",
    "    \n",
    "    ax1 = fig.add_subplot(7, columns, 5)\n",
    "    cb1 = matplotlib.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                    norm=normalize,\n",
    "                                    orientation='horizontal')\n",
    "    \n",
    "    if show :\n",
    "        plt.show()\n",
    "\n",
    "    if filename != None :\n",
    "        fig.savefig(filename)\n",
    "\n",
    "def extract_data(config, feature=True, pure=False) :\n",
    "    result = pd.DataFrame()\n",
    "    for priority in config :\n",
    "        for set_value in config[priority] :\n",
    "            try :\n",
    "                source = get_source(priority, set_value)\n",
    "                mrk_filenames, nmf_filenames = get_filenames(source)\n",
    "\n",
    "                if len(mrk_filenames) == 0 or len(nmf_filenames) == 0:\n",
    "                    print(priority, set_value, \"mrk\", len(mrk_filenames), \"nmf\", len(nmf_filenames))\n",
    "                    continue \n",
    "\n",
    "                set_df = pd.DataFrame()\n",
    "                for mrk, nmf in zip(mrk_filenames, nmf_filenames) :\n",
    "                    try :\n",
    "                        df = extract_feature(mrk, nmf)\n",
    "                        set_df = pd.concat([set_df, df])\n",
    "                    except :\n",
    "                        traceback.print_exc()\n",
    "                        print(nmf)\n",
    "\n",
    "                set_df = set_df[[\"location_x\", \"location_y\", \"PCI\", \"RSRP\", \"RSRQ\", \"SNR\", \n",
    "                                 \"timestamp\", \"filename\"]]\n",
    "\n",
    "                if feature :\n",
    "                    if not pure :\n",
    "                        set_df = add_features_summary(set_df, priority, set_value)\n",
    "                    else :\n",
    "                        set_df = add_features(set_df, priority, set_value)\n",
    "                        set_df[\"priority\"] = priority\n",
    "                        set_df[\"set\"] = set_value\n",
    "\n",
    "                result = pd.concat([result, set_df])\n",
    "            except :\n",
    "                print(priority, set_value)\n",
    "                traceback.print_exc()\n",
    "                return df \n",
    "            \n",
    "    if pure :\n",
    "        result = result.drop([\"timestamp\", \"filename\"], axis=1)\n",
    "        result[\"PCI\"] = result[\"PCI\"].astype('int32')\n",
    "    return result\n",
    "\n",
    "def get_data(config, pure, refresh) :\n",
    "    if refresh :\n",
    "        df = extract_data(config=config, feature=True, pure=pure)\n",
    "#         cols = [\"location_x\", \"location_y\", \"PCI\", \"RSRP\", \"RSRQ\", \"SNR\", \n",
    "#            'Power_37', 'Power_38', 'Power_39', 'Power_40', 'Power_41', 'Power_42',\n",
    "#            '37_beam0', '37_beam32', '37_beam64', '37_beam96', '37_beam128',\n",
    "#            '38_beam0', '38_beam32', '38_beam64', '38_beam96', '38_beam128',\n",
    "#            '39_beam0', '39_beam32', '39_beam64', '39_beam96', '39_beam128',\n",
    "#            '40_beam0', '40_beam32', '40_beam64', '40_beam96', '40_beam128',\n",
    "#            '41_beam0', '41_beam32', '41_beam64', '41_beam96', '41_beam128',\n",
    "#            '42_beam0', '42_beam32', '42_beam64', '42_beam96', '42_beam128',\n",
    "#            'Distance_37', 'Distance_38', 'Distance_39', 'Distance_40', 'Distance_41', 'Distance_42',  \n",
    "#            'Angle_37', 'Angle_38', 'Angle_39', 'Angle_40', 'Angle_41', 'Angle_42', 'set']\n",
    "\n",
    "#         df_data = df_data[cols]\n",
    "        df.to_csv(\"db/all_summary.csv\")\n",
    "        return df\n",
    "    else :\n",
    "        return pd.DataFrame.from_csv(\"db/all_summary.csv\")\n",
    "    \n",
    "def print_size_per_priority(priority_config, df) :\n",
    "    for p in priority_config :\n",
    "        for s in priority_config[p] :\n",
    "            print(p, s, len(df[(df[\"priority\"]==p) & (df[\"set\"]==s)]))\n",
    "            \n",
    "def generate_predicted_data_pci(predicted_set_config, all_x_pci, refresh=False) :\n",
    "    all_x_pci_dict = {}\n",
    "    for priority in predicted_set_config :\n",
    "        for set_value in predicted_set_config[priority] :\n",
    "            found = True\n",
    "            name = \"db/pci_prio_%d_set_%d.csv\" % (priority, set_value)\n",
    "            try :\n",
    "                x_rsrp = pd.DataFrame.from_csv(name)\n",
    "            except :\n",
    "                found = False \n",
    "                \n",
    "            if refresh or not found :\n",
    "                x_rsrp = add_features(pd.DataFrame(all_x_pci), priority, set_value) \n",
    "                x_rsrp[\"set\"] = set_value\n",
    "                x_rsrp.to_csv(name)\n",
    "            \n",
    "            all_x_pci_dict[(priority, set_value)] = x_rsrp\n",
    "    return all_x_pci_dict\n",
    "\n",
    "def merge_with_pci_groundtruth(rsrp_data, x_df, p, i, whitelist=whitelist_PCI) :\n",
    "    pci_ground_truth = rsrp_data[(rsrp_data[\"priority\"]==p) & (rsrp_data[\"set\"]==i)]\n",
    "    pci_ground_truth = pci_ground_truth[pci_ground_truth[\"PCI\"].isin(whitelist)]\n",
    "    pci_ground_truth = pci_ground_truth[[\"location_x\", \"location_y\", \"PCI\"]]\n",
    "    pci_ground_truth = pci_ground_truth.drop_duplicates()\n",
    "    pci_ground_truth[\"PCI\"] = pci_ground_truth[\"PCI\"].apply(lambda x : pci_encode[x])\n",
    "    pci_ground_truth = pci_ground_truth.groupby([\"location_x\", \"location_y\"]).agg({'PCI': list}).reset_index()\n",
    "\n",
    "    def merge_pci(x):\n",
    "        return x[\"PCI_x\"] if type(x[\"PCI_y\"]) != list or x[\"PCI_x\"] in x[\"PCI_y\"] else x[\"PCI_y\"][0]\n",
    "    \n",
    "    x_df = pd.merge(x_df, pci_ground_truth, on=[\"location_x\", \"location_y\"], how=\"left\")\n",
    "    x_df[\"final_PCI\"] = x_df.apply(lambda x : merge_pci(x),axis=1)\n",
    "    x_df = x_df[[\"location_x\", \"location_y\", \"final_PCI\"]]\n",
    "    x_df = x_df.rename(columns={\"final_PCI\":\"PCI\"})\n",
    "    x_df[\"PCI\"] = x_df[\"PCI\"].apply(lambda x : pci_decode[int(x)])\n",
    "    return x_df\n",
    "\n",
    "def generate_predicted_data_rsrp(rsrp_data, predicted_set_config, \n",
    "                                 x_coord_list, y_coord_list, all_y_pci, refresh=False) :\n",
    "    all_x_rsrp_dict = {}\n",
    "    for p in predicted_set_config :\n",
    "        for s in predicted_set_config[p] :\n",
    "            found = True\n",
    "            name = \"db/rsrp_prio_%d_set_%d.csv\" % (p, s)\n",
    "            try :\n",
    "                x_rsrp = pd.DataFrame.from_csv(name)\n",
    "            except :\n",
    "                found = False \n",
    "                \n",
    "            if refresh or not found :\n",
    "                x_rsrp = pd.DataFrame({'location_x':x_coord_list, \n",
    "                                       'location_y':y_coord_list,\n",
    "                                       'PCI':all_y_pci[(p, s)]})\n",
    "                \n",
    "                try :\n",
    "                    x_rsrp = merge_with_pci_groundtruth(rsrp_data, x_rsrp, p, s)\n",
    "                except :\n",
    "                    print(p, s)\n",
    "                    traceback.print_exc()\n",
    "                    \n",
    "                x_rsrp = add_features(x_rsrp, p, s)\n",
    "                x_rsrp['set'] = s\n",
    "                x_rsrp.to_csv(name)\n",
    "                \n",
    "            all_x_rsrp_dict[(p,s)] = x_rsrp\n",
    "    return all_x_rsrp_dict\n",
    "\n",
    "def merge_with_rsrp_groundtruth(rsrq_data, x_rsrq, p, i, whitelist=[301, 302]) :\n",
    "    rsrp_ground_truth = rsrq_data[(rsrq_data[\"priority\"]==p) & (rsrq_data[\"set\"]==i)]\n",
    "    rsrp_ground_truth = rsrp_ground_truth[rsrp_ground_truth[\"PCI\"].isin(whitelist_PCI)]\n",
    "    rsrp_ground_truth = rsrp_ground_truth[[\"location_x\", \"location_y\", \"PCI\", \"RSRP\"]]\n",
    "    rsrp_ground_truth = rsrp_ground_truth.drop_duplicates()\n",
    "    rsrp_ground_truth = rsrp_ground_truth.groupby([\"location_x\", \"location_y\", \"PCI\"]).agg(\n",
    "        {'RSRP' : np.max}).reset_index()\n",
    "    rsrp_ground_truth = rsrp_ground_truth.groupby([\"location_x\", \"location_y\"]).agg(\n",
    "        {'PCI' : list, 'RSRP' : list}).reset_index()\n",
    "    rsrp_ground_truth[\"max_PCI\"] = rsrp_ground_truth.apply(lambda x : x[\"PCI\"][np.argmax(x[\"RSRP\"])], axis=1)\n",
    "    rsrp_ground_truth[\"max_RSRP\"] = rsrp_ground_truth.apply(lambda x : max(x[\"RSRP\"]), axis=1)\n",
    "    rsrp_ground_truth = rsrp_ground_truth[[\"location_x\", \"location_y\", \"max_PCI\", \"max_RSRP\"]]\n",
    "    \n",
    "    x_rsrq = pd.merge(x_rsrq, rsrp_ground_truth, on=[\"location_x\", \"location_y\"], how=\"left\")\n",
    "    x_rsrq[\"final_PCI\"] = x_rsrq.apply(lambda x : x[\"max_PCI\"] if x[\"max_PCI\"] > 0  else x[\"PCI\"], axis=1)\n",
    "    x_rsrq[\"final_RSRP\"] = x_rsrq.apply(\n",
    "        lambda x : x[\"max_RSRP\"] if x[\"final_PCI\"] == x[\"max_PCI\"] else x[\"pred_RSRP\"], axis=1)\n",
    "    x_rsrq = x_rsrq[[\"location_x\", \"location_y\", \"final_PCI\", \"final_RSRP\"]]\n",
    "    x_rsrq = x_rsrq.rename(columns={\"final_PCI\":\"PCI\", \"final_RSRP\" : \"RSRP\"})\n",
    "    x_rsrq[\"PCI\"] = x_rsrq[\"PCI\"].astype('int64')\n",
    "\n",
    "    return x_rsrq\n",
    "\n",
    "def generate_predicted_data_rsrq(rsrq_data, predicted_set_config, \n",
    "                                 x_coord_list, y_coord_list, all_pred_rsrp_dict, refresh=False) :\n",
    "    all_x_rsrq_dict = {}\n",
    "    for p in predicted_set_config :\n",
    "        for s in predicted_set_config[p] :\n",
    "            found = True\n",
    "            name = \"db/rsrq_prio_%d_set_%d.csv\" % (p, s)\n",
    "            try :\n",
    "                x_rsrq = pd.DataFrame.from_csv(name)\n",
    "            except :\n",
    "                found = False \n",
    "                \n",
    "            if refresh or not found :\n",
    "                x_rsrq = pd.DataFrame(all_pred_rsrp_dict[(p, s)])\n",
    "                \n",
    "                try :\n",
    "                    x_rsrq = merge_with_rsrp_groundtruth(rsrq_data, x_rsrq, p, s)\n",
    "                except :\n",
    "                    print(p, s)\n",
    "                    x_rsrq = x_rsrq.rename(columns={\"pred_RSRP\" : \"RSRP\"})\n",
    "                    traceback.print_exc()\n",
    "                    \n",
    "                x_rsrq = add_features(x_rsrq, p, s)\n",
    "                x_rsrq['set'] = s\n",
    "                \n",
    "                x_rsrq.to_csv(name)\n",
    "                \n",
    "            all_x_rsrq_dict[(p,s)] = x_rsrq\n",
    "    return all_x_rsrq_dict\n",
    "        \n",
    "def merge_with_rsrq_groundtruth(snr_data, x_snr, p, i, whitelist=[301, 302]) :\n",
    "    rsrq_ground_truth = snr_data[(snr_data[\"priority\"]==p) & (snr_data[\"set\"]==i)]\n",
    "    rsrq_ground_truth = rsrq_ground_truth[rsrq_ground_truth[\"PCI\"].isin(whitelist_PCI)]\n",
    "    rsrq_ground_truth = rsrq_ground_truth[[\"location_x\", \"location_y\", \"PCI\", \"RSRP\", \"RSRQ\"]]\n",
    "    rsrq_ground_truth = rsrq_ground_truth.drop_duplicates()\n",
    "    rsrq_ground_truth = rsrq_ground_truth.groupby([\"location_x\", \"location_y\", \"PCI\"]).agg(\n",
    "        {'RSRP' : np.max, 'RSRQ' : np.max}).reset_index()\n",
    "    rsrq_ground_truth = rsrq_ground_truth.groupby([\"location_x\", \"location_y\"]).agg(\n",
    "        {'PCI' : list, 'RSRP' : list, 'RSRQ' : list}).reset_index()\n",
    "    rsrq_ground_truth[\"max_PCI\"] = rsrq_ground_truth.apply(lambda x : x[\"PCI\"][np.argmax(x[\"RSRP\"])], axis=1)\n",
    "    rsrq_ground_truth[\"max_RSRP\"] = rsrq_ground_truth.apply(lambda x : max(x[\"RSRP\"]), axis=1)\n",
    "    rsrq_ground_truth[\"max_RSRQ\"] = rsrq_ground_truth.apply(lambda x : max(x[\"RSRQ\"]), axis=1)\n",
    "    rsrq_ground_truth = rsrq_ground_truth[[\"location_x\", \"location_y\", \"max_PCI\", \"max_RSRP\", \"max_RSRQ\"]]\n",
    "    \n",
    "    x_snr = pd.merge(x_snr, rsrq_ground_truth, on=[\"location_x\", \"location_y\"], how=\"left\")\n",
    "    x_snr[\"final_PCI\"] = x_snr.apply(lambda x : x[\"max_PCI\"] if x[\"max_PCI\"] > 0  else x[\"PCI\"], axis=1)\n",
    "    x_snr[\"final_RSRP\"] = x_snr.apply(\n",
    "        lambda x : x[\"max_RSRP\"] if x[\"final_PCI\"] == x[\"max_PCI\"] else x[\"RSRP\"], axis=1)\n",
    "    x_snr[\"final_RSRQ\"] = x_snr.apply(\n",
    "        lambda x : x[\"max_RSRQ\"] if x[\"final_PCI\"] == x[\"max_PCI\"] else x[\"pred_RSRQ\"], axis=1)\n",
    "    x_snr = x_snr[[\"location_x\", \"location_y\", \"final_PCI\", \"final_RSRP\", \"final_RSRQ\"]]\n",
    "    x_snr = x_snr.rename(columns={\"final_PCI\":\"PCI\", \"final_RSRP\" : \"RSRP\", \"final_RSRQ\" : \"RSRQ\"})\n",
    "    x_snr[\"PCI\"] = x_snr[\"PCI\"].astype('int64')\n",
    "\n",
    "    return x_snr\n",
    "\n",
    "def generate_predicted_data_snr(snr_data, predicted_set_config, \n",
    "                                 x_coord_list, y_coord_list, all_pred_snr_dict, refresh=False) :\n",
    "    all_x_snr_dict = {}\n",
    "    for p in predicted_set_config :\n",
    "        for s in predicted_set_config[p] :\n",
    "            found = True\n",
    "            name = \"db/snr_prio_%d_set_%d.csv\" % (p, s)\n",
    "            try :\n",
    "                x_snr = pd.DataFrame.from_csv(name)\n",
    "            except :\n",
    "                found = False \n",
    "                \n",
    "            if refresh or not found :\n",
    "                x_snr = pd.DataFrame(all_pred_snr_dict[(p, s)])\n",
    "                \n",
    "                try :\n",
    "                    x_snr = merge_with_rsrq_groundtruth(snr_data, x_snr, p, s)\n",
    "                except :\n",
    "                    print(p, s)\n",
    "                    x_snr = x_snr.rename(columns={\"pred_RSRQ\" : \"RSRQ\"})\n",
    "                    traceback.print_exc()\n",
    "                    \n",
    "                x_snr = add_features(x_snr, p, s)\n",
    "                x_snr['set'] = s\n",
    "                \n",
    "                x_snr.to_csv(name)\n",
    "                \n",
    "            all_x_snr_dict[(p,s)] = x_snr\n",
    "    return all_x_snr_dict\n",
    "        \n",
    "def save_to_pickle(all_y, filename) :\n",
    "    with open(\"db/\"+filename+\".pkl\", 'wb') as f:\n",
    "        pickle.dump(all_y, f)\n",
    "        \n",
    "def load_from_pickle(filename) :\n",
    "    with open(\"db/\"+filename+\".pkl\", 'rb') as f:\n",
    "        datastore = pickle.load(f)\n",
    "    return datastore\n",
    "\n",
    "def merge_count(df, group, value, columns) :\n",
    "    df_count = pd.DataFrame(df.groupby(group)[value].count()).reset_index()\n",
    "    df_count.columns = group + [\"%s_min\" % (\"_\".join(group))] if columns == None else group + columns\n",
    "    df = df.merge(df_count, on=group, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def merge_agg(df, group, value, aggregates) :\n",
    "    df_count = pd.DataFrame(df.groupby(group)[value].agg(aggregates)).reset_index()\n",
    "    df_count.columns = group + aggregates\n",
    "    df = df.merge(df_count, on=group, how=\"left\").fillna(0)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
